Cumulants of Hawkes point processes
Stojan Jovanovic
Bernstein Center Freiburg  Faculty of Biology
University of Freiburg 79104 Freiburg im Breisgau Germany and
KTH Royal Institute of Technology 10691 Stockholm Sweden
John Hertz
Institute for Neuroscience and Pharmacology and Niels Bohr Institute
University of Copenhagen 2100 Copenhagen Denmark and
NORDITA KTH Royal Institute of Technology and Stockholm University 10691 Stockholm Sweden
Stefan Rotter
Bernstein Center Freiburg  Faculty of Biology
University of Freiburg 79104 Freiburg im Breisgau Germany
We derive explicit closed-form expressions for the cumulant densities of a multivariate self-
exciting Hawkes point process generalizing a result of Hawkes in his earlier work on the covariance
density and Bartlett spectrum of such processes To do this we represent the Hawkes process in
terms of a Poisson cluster process and show how the cumulant density formulas can be derived
by enumerating all possible family trees representing complex interactions between point events
We also consider the problem of computing the integrated cumulants characterizing the average
measure of correlated activity between events of dierent types and derive the relevant equations
INTRODUCTION
The Hawkes point process was rst introduced in 1
as a model of chain-reaction-like phenomena in which
the occurrence of an event increases the likelihood of
more such events happening in the future This intrinsic
self-exciting property has made Hawkes processes ap-
pealing to a wide variety of researchers dealing with data
exhibiting strong temporal clustering Although it was
originally used to model the dynamics of aftershocks that
accompany strong earthquakes 2 3 it has since found
application to many other problems including accretion
disc formation 4 gene interactions 5 social dynam-
ics 6 insurance risk 7 8 corporate default cluster-
ing 9 10 market impact 11 high-frequency nancial
data 12 micro-structure noise 13 crime 14 generic
properties of high-dimensional inverse problems in sta-
tistical mechanics 15 and dynamics of neural networks
16 17 There is also recent theoretical work exploring
generic mathematical properties of the process in its own
respect 1820
As the areas of application of Hawkes models continue
to grow it becomes increasingly important to understand
the probabilistic behavior of the process Unfortunately
despite its ubiquity the mathematical properties of the
Hawkes process are still not fully known
In fact the
same dynamical characteristics that make it such a useful
model in practice are the ones that complicate formal
analysis Hawkes processes do not except in some special
 stojanjovanovicbcfuni-freiburgde
 hertznbidk
 stefanrotterbiologieuni-freiburgde
cases see 21 possess the Markov property making it
impossible to study them using standard techniques
Recently quite a few methods have been devised to cir-
cumvent this problem there are now many well known re-
sults describing Hawkes process stability 22 long-term
behavior 7 23 and large deviation properties 24 Yet
since the early works of Hawkes himself on the covari-
ance density and Bartlett spectrum 25 of self-exciting
processes 1 26 few have tried to further elucidate their
statistical properties
In his work Adamopoulos 27
for example attempts to derive the probability generat-
ing functional of the Hawkes process but manages only
to represent it implicitly as a solution of an intractable
functional equation Errais et al 10 using the elegant
theory of ane jump processes show that the moments
of Hawkes processes can be computed by solving a sys-
tem of non-linear ODEs Once again however explicit
formulas turn out to be unobtainable by analytic means
Lastly Saichev and Sornette 28 29 using the alterna-
tive Poisson cluster representation of self-exciting pro-
cesses show that the moment generating function of the
Hawkes process satises a transcendental equation which
does not admit an explicit solution
Statistical behavior of for example Hawkes process
moments and cumulants is of some importance in neuro-
science where the problem of quantifying levels of syn-
chronization of action potentials has become very perti-
nent It has been shown that nerve cells can be extremely
sensitive to synchronous input from large groups of neu-
rons 30 More precisely a neurons ring rate prole
depends to a large degree on higher order correlations
amongst the presynaptic spikes 31 Of course which
synchronous patterns are favored by the network is also
determined by its connection structure While the con-
tribution of specic structural motifs to the emergence
of pairwise correlations ie two-spike patterns has al-
ready been dissected 16 no such result exists in the case
of more complex patterns stemming from correlations of
higher order
In this paper we derive analytic formulas for the nth
order cumulant densities of a linear self-exciting Hawkes
process with arbitrary interaction kernels generalizing
the result in 26 Inspired by the approach of Saichev
et al we do this by utilizing the Poisson cluster process
representation 32 which simplies calculations consid-
erably Furthermore we show that the cumulant densi-
ties admit a natural and intuitive graphical representa-
tion in terms of the branching structure of the underlying
process and describe an algorithm that facilitates practi-
cal computation Finally we generalize the result in 16
by showing that the integrated cumulant densities can be
expressed in terms of formal sums of topological motifs of
a graph induced by specifying the physical interactions
between dierent types of point events
II PRELIMINARIES
Basic denitions
ie that the probability of two or more events arriving
simultaneously is negligibly small Intuitively therefore
the conditional rate function represents the probability of
a new event occurring in the innitesimally near future
given the information about all events in the past
Furthermore from our previous considerations it also
follows that dN t is up to rst order a Bernoulli ran-
dom variable and therefore
cid104dN tcid105  PdN t  1  Pan event occurs at t
A The multivariate Hawkes process
As was pointed out in 32 the Hawkes process can be
dened in two equivalent ways either by specifying its
conditional rate function or as a Poisson cluster process
generated by a certain branching structure
1 The conditional rate representation
Following 1 and 26 let us consider a d-dimensional
point process s  stt0 with rate function tt0
dened by
cid90 t
cid90 t
t   
Gt  u  dNu
  
Gt  u  sudu
where  denotes the d-dimensional base rate vector with
positive entries i  0 and Gt is an d  d matrix of
non-negative integrable functions gijt with support on
R called the interaction kernel In principle therefore
the rate t should always remain positive but models
for which the probability of negative values is suciently
small may be useful approximations 34
the conditional rate function it we nd that i
Rewriting equation 6 in terms of the components of
Consider a sequence T  Tnn1 of positive random
variables representing times of random occurrences of a
certain event Alternatively T can be also thought of as
as collection of random points on the positive half-line
R By superposing all event times in the sequence we
obtain the point process s  stt0 formally dened
by setting
st 
t  Tn
where tTn denotes the Dirac delta function centered
at the random point Tn
It is easy to see that the number of events occurring
before time t is given by
cid88
cid90 t
N t 
sudu  n  Tn  t
The conditional probability given the past activity of
a new event occurring in the interval t tdt is given by
the conditional rate function tt0 More specically
we have up to rst order 33
it  i 
gijt  udN ju
From equations 3 and 8 we can now see that
cid90 t
dcid88
base rate
cid122cid125cid124cid123
cid90 t
dcid88
cid124
PdN t  1Ht  tdt
where Ht represents the history of the point process s up
to time t Additionally we assume that
PdN it  1Ht
PdN t  2Ht  odt
gijt  udN ju
cid123cid122
inuence of past Ht
cid125
ie that the probability of an event of type i occurring
at time t is simply the sum of a constant base rate and
a convolution of the complete history of the process with
the interaction kernel Gt whose component gijt de-
scribes the increase of the likelihood of type i events at
t caused by a type j event occurring at 0 Note that in
the special case of no interactions gijt  0 we recover
the denition of a multivariate Poisson process with con-
stant rate  In this case however the conditional rate
function is independent both of time and of the history
2 The cluster process representation
Let us consider a Poisson cluster process C which
evolves in the following way 35 see also Figure 1 
1 Let I k be a realization on the interval 0 T  of a
homogeneous Poisson process with rate k We will
call points in I k immigrants of type k
2 For every k each immigrant x  I k generates a
x  All such clusters are mutually
cluster of points C k
independent
3 The clusters C k
x are generated according to the
following branching structure
 Each cluster C k
x consists of generations of
ospring of all types of the immigrant x which
itself belongs to generation 0
 Recursively given the immigrant x and the
ospring of generation 1 2  n of all types
every child y of generation n and type j
produces i its own ospring of generation
n  1 and type i by generating a realization of
an inhomogeneous Poisson process Oij with
rate t  gijt  y
In other words the
probability of there being at time t a type i
ospring event of generation n  1 caused by
a type j event y of generation n is equal to
gijt  ydt
4 The point process C is equal to the superposition
of all points in all generated clusters ie
cid88
For example if C were used to model the dynamics
of a spiking neuronal network the immigrants I k would
represent all the spikes of neuron k caused by constant
external input to the network and the clusters C k
subsequent spikes caused by action potential propaga-
tion through the network via synaptic connections
to show see eg 32 that by letting i and t  0
Having dened the cluster process C it is then possible
FIG 1 Color online Evolution of a Poisson cluster process
on a network with 4 nodes and 6 directed links
Left column Hatched nodes are active and dashed links are
transmitting a signal to all their respective neighbors
Right column A cluster generated by the arrival of an immi-
grant from node A evolves sequentially as new ospring are
produced
Row 1 A type A immigrant arrives providing the seed from
which a new cluster will emerge
Row 2 The type A immigrant generates 1st generation o-
spring of types B and D respectively Together these con-
stitute the 1st generation of events
Row 3 The 1st generation type D event generates a single
ospring event of type C The event of type B creates two
ospring of types A and C respectively
Row 4 Finally the 2nd generation type A event is the only
one to generate 3 ospring events of types B C and D re-
spectively
Bottom A time sequence of events generated in this 4 gen-
eration long evolution here displayed by means of a raster
plot which indicates the events generated by each node on
the time axis
and assuming that the spectral radius G ie
largest eigenvalue of the integrated kernel matrix
cid104XBcid105 
where the sum goes over all partitions  of the set
1  n    denotes the number of blocks of a given
partition and
cid43
cid42cid89
A dual formula expressing moments in terms of cumu-
lants reads
cid88
cid89
cid104Xncid105 
where kXB denotes the cumulant of those components
of X whose indices are in B
The cumulant kXn is a natural generalization to
higher dimensions of the covariance covX1 X2 of two
variables
Indeed if we set n  2 X  X1 X2 and apply for-
mula 16 we obtain
kX1 X2  1  1111cid104X1X2cid105
 2  1121cid104X1cid105cid104X2cid105
as 1  1 2 and 2  12 are the only par-
titions of the set 1 2 Also obviously 1  1 and
2  2 Thus
kX1 X2  cid104X1X2cid105  cid104X1cid105cid104X2cid105  covX1 X2
For a given time vector t  t1  tn and multi-
index i  i1  in we now dene the the nth or-
der cumulant density of the Hawkes process denoted by
kit by letting
kdN i1 t1  dN in tn
kit 
where we used dt to denote the dierential dt1  dtn
As in the general case the cumulant density kit is
used to quantify the mutual dependence of random events
of types i1  in at times t1  tn
it  lim
Pevent of type i in t t  Ht
cid90 
is strictly less than 1 then it must be equal to the
conditional rate function in equation 8 Furthermore
the corresponding point process will also be stationary
In other words we will have
cid104Ntcid105
 cid104tcid105    I  G
1
where I denotes the d  d identity matrix In what fol-
lows we will always assume that we are working with
a stationary version of a Hawkes process More speci-
cally we will assume that G  1 and consequently
that the matrix I  G1 can be expanded in terms of
powers of the integrated kernel matrix G ie
cid88
I  G
Note that the matrix G has a very useful interpretation
which follows from the denition of the Poisson cluster
process - its component gij represents the average to-
tal number of events of type i in the second generation
caused by a rst generation type j event Thus the
components of the nth matrix power Gn equal the aver-
age total number of type i ospring within n subsequent
generations of a rst generation type j event
From our previous considerations it now follows that
by requiring that G  1 or equivalently that the
series 15 converges we in fact assume that each event
of a given type produces only nitely many events of any
other type after an innite number of generations
III THE HAWKES PROCESS CUMULANT
For example from equations 20 and 5 we can see
DENSITY
that for i  1 2 t  t1 t2 and dt  dt1dt2
Consider now an arbitrary n-dimensional random vec-
tor X  X1  Xn  Xn where we used the symbol
n to denote the set 1  n The cumulant of order
n denoted by kXn is a general measure of statisti-
cal dependence of the components of X
It is dened
combinatorially as see 36 page 27
kXn 
  11
cid104XBcid105 
cid88
1 cid89
kitdt Ptype 1 event at t1 type 2 event at t2
Ptype 1 event at t1Ptype 2 event at t2
The formulas for the nth order cumulant density kit
however get more and more complicated with increasing
n as the number of set partitions involved grows supra-
exponentially
To illustrate this point we set n  3 i  1 2 3 and
t  t1 t2 t3 Then from 16 we have
kitdt  cid104dN 1t1dN 2t2dN 3t3cid105
 cid104dN 1t1dN 2t2cid105cid104dN 3t3cid105
 cid104dN 1t1dN 3t3cid105cid104dN 2t2cid105
 cid104dN 2t2dN 3t3cid105cid104dN 1t1cid105
 2cid104dN 1t1cid105cid104dN 2t2cid105cid104dN 3t3cid105
To alleviate the problem of increasing complexity we
use the cluster process representation to come up with
a useful and intuitive expression for the density kit in
terms of the cluster processs branching structure
First o note that the only way that events t1  tn
of types i1  in can be statistically dependent is if
they all belong to the same cluster ie
if they are all
ospring possibly of dierent generations of a single
original immigrant
More specically we can show that see Appendix A
for every multi-index i  i1  in and every vector
t  t1  tn
kitdt  Pcid8Ei
t  C i
cid9 
t  k there is a type ik event at time tk
t   cluster C such that k tk  C
This result now provides us with a practical way of
computing kitdt
For example in the case when n  2 we have that
kijt1 t2dt1dt2 is equal to the probability of there being
a type i event at time t1 a type j event at time t2 and
that both of these events are descendant from a common
immigrant Therefore in order to compute the 2nd order
cumulant density we need to sum up the probabilities of
all possible family trees which contain events t1 and t2
see Figure 2
In order to formalize this computation we dene
Ptype j event at 0 causes type i event at t
Gcid63nt
cid88
and therefore by induction
t  It  Gt  Gcid632t  Gcid633t   ij
Gcid63nt
cid88
where ij extracts component i j of a given matrix
and Gcid63nt denotes the nth convolution power of the
interaction kernel Gt dened recursively by
Furthermore noting that Ptype k immigrant at x
is by construction equal to kdx we obtain the prob-
ability of an immigrant arriving at any point in time
generating an event of type m at time u It equals
FIG 2 A schematic representation of all possible family
trees containing events t1 and t2 Two concrete examples of
family trees mapping to the same general schema are given in
the second row The root x denotes the original immigrant
and u the branching point in the family tree of immigrant x
leading to the appearance of ospring t1 and t2 Note that
each link connecting two nodes can be in theory any number
of generations long
Gcid630t  It
cid90 t
Gcid63nt 
Gcid63n1t  s  Gsds
Indeed if we dene pij
n t to be equal to the probability
that an event of type j at 0 after n generations causes
a type i event at t we have
 ijt  Itij
 Gtij
cid90 t
dcid88
Gt  sikGskjds  Gcid632tij
T12xut1t2xuvt1t2xuvt1wyt2cid90
dcid88
dcid88
uxdx 
I  G
1mkk  m
cid90
ie it is the mth component of the stationary rate vector
 in 14 where the rst equality in the previous equation
follows from
uxdx 
Gcid63nu  xmkdx
Gnmk  I  G
1mk
cid90
cid88
cid88
dcid88
cid90
Computing the probability of the family tree T12 in
Figure 2 is now straightforward recalling the denition of
t and taking into account our previous considerations
kijt1 t2 
P T12
t1uRjm
t2udu
recovering a classical and well known result on the
covariance density of the Hawkes process see 26
A big advantage of our approach however
is that
it can be used to compute cumulant densities of orders
greater than 2
For example in order to compute the 3rd order density
kijkt1 t2 t3 we start as in the 2-dimensional case by
enumerating all possible family trees with leaves t1 t2
and t3 In this case however there are in total 4 dierent
possibilities see Figure 3
We can now proceed in much the same way as before
summing up the probabilities of all possible trees in order
to derive the desired formula We dene t  t1 t2 t3
dt  dt1dt2dt3 and
cid88
Gcid63nt
t  Rij
t  ijt 
nally obtaining
FIG 3 A schematic representation of all possible family
trees containing events t1 t2 and t3 Once again the root x
denotes the original immigrant nodes u and v represent the
branching points in the family tree of immigrant x and each
link between two nodes can be any number of generations
It is important to point out that equation 39 can
be derived in a dierent albeit a more tedious way using
martingale theory arguments generalizing the derivation
of Bacry et al
in 37 for the second order cumulant
density
The newly introduced function ij
t corresponds to the
probability of a type j event at 0 generating a type i
event at t after at least one generation
The appearance of such a term in the above equations
is a consequence of the fact that for instance contracting
the link between nodes u and v in tree T123 to a point
turns it into T123 which is already accounted for Thus
in order to avoid counting certain congurations twice
we must introduce a sti link between the two internal
nodes u and v in trees T123 T213 and T312
By generalizing the above considerations it is possible
to construct a general procedure for computing the nth
order cumulant density ki1in t1  tn
1 For a given n  2 generate all possible rooted trees
T with n leaves
2 Label the leaves of T with ordered pairs ik tk in
arbitrary order Label the internal nodes including
the root of T arbitrarily
3 For every tree T  construct an integral term IT 
according the the following pseudo-algorithm 
a Set IT  1
b For every edge in T connecting a node v of
type jv to a leaf tk of type ik 
kijkt 
P T123
P T213
P T312
P T123
cid19
cid19
cid19
t2vRkm
t3vmn
vudv
t1vRkm
t3vmn
vudv
t1vRjm
t2vmn
vudv
cid18cid90
cid18cid90
cid18cid90
dcid88
dcid88
dcid88
dcid88
cid90
cid90
cid90
cid90
t1uRjm
t2uRkm
t3udu
IT  IT  Rikjv
tkvdv
T123xut1t2t3T123xut1vt2t3T213xut2vt1t3T312xut3vt1t2n Terms in kit
39 208
660 302
12 818 912
282 137 824
FIG 4 Number of terms in kit for a given n - from 38
c For every edge in T connecting an internal
node u of type ju to another internal node v
of type jv 
IT  IT  jvju
vudu
d Let x be the root of T  Set
IT  IT  jx
e Integrate IT with respect to the variable du
for every internal node u
f Sum over all ju for every internal node u
g Sum over all jx
4 Add up all integral terms IT for every rooted tree
T  generated in the rst step to obtain the nth
order cumulant density
The principal diculty of the above procedure lies its
rst step ie
in the enumeration of all topologically
distinct rooted trees with n labeled leaves While there
are known algorithms that can tackle this problem see
eg the classic text by Felsenstein 38 the number of
terms grows very quickly with increasing n see Figure 4
and thus computing kit quickly becomes impractical
INTEGRATED CUMULANTS AS SUMS OF
TOPOLOGICAL MOTIFS
Let kit be for a given time vector t  t1  tn
and multi-index i  i1  in the nth order cumulant
density of a d-dimensional Hawkes process We dene
the integrated cumulant of order n denoted simply by
ki by setting
kitdt
Note that ki can be seen as the n-dimensional Laplace
transform at zero of kit Indeed if we denote
cid90
cid90
Lkit 
where   1  n  Cn and   t  cid80
tkitdt
have clearly
ki  L0kit
Thus if we dene
R11
 R1d
 Rdd
  t  Rt  It
i iti we
we can by Laplace transforming the covariance density
kijt1 t2 prove see Appendix B that
mRimRjm
where we set
R  I  G
1  L0Rt
Expanding R in powers of G we get
dcid88
dcid88
cid88
cid88
cid88
TT m
mGkimGljm
Interpreting now the matrix power Gl in the sense of
graph theory ie as a matrix whose component i j
corresponds to the sum of lengths of all paths from node
j to node i in exactly l steps we see that the integrated
covariance density kij can be equivalently represented as
where the sum goes over the set T m
ij of all rooted trees
T with root m containing nodes i j Here wT 
denotes the weight of tree T  dened as the product of
weights of all edges contained in T  times the weight of
the root m dened as being equal to m
The graph H with adjacency matrix G can be thought
of as follows Each node i  1  n in H corresponds
to a type of event in the underlying Hawkes process and
the existence of an edge eij from j to i indicates the
possibility of generating type i events from those of type
j Starting in node j traversing the corresponding edge
to reach node i is equivalent to generating gij type i
ospring of a type j immigrant Therefore each path
through graph H represents a specic bloodline of a
type m immigrant while a tree T  T m
ij accounts for the
possibility of the bloodline splitting somewhere along the
way concluding in after a certain number of generations
in ospring of both types i and j The previous formula
tells us that the sum of weights of all such trees is equal
to the integrated covariance kij
Now reasoning in much the same way as before we
have for kijk
dcid88
dcid88
dcid88
dcid88
mRimRjmRkm
nRimRjmmnRkn
nRjmRkmmnRin
nRimRkmmnRjn
where   I  G1  I  L0t Once again ex-
panding R and  in powers of G yields
cid88
TT m
cid88
where T m
ijk is the set of all rooted trees with root m
containing nodes i j k and w is the already dened
weight function
It is now easy to see that the general result is of the
TT m
where i  i1  in and T m
rooted trees with root m containing nodes i1  in
i  T m
i1in is the set of all
simplifying the expressions for the corresponding cumu-
lant densities Moreover and not surprisingly we demon-
strated that integrated cumulants likewise admit a repre-
sentation in terms of a formal sum of topological motifs
generalizing previous work on the topological expansion
of the integrated covariance 16
The problem of quantifying higher-order correlations is
of some importance in theoretical neuroscience Indeed
it has long been suggested 39 40 that understanding the
cooperative dynamics of populations of neurons would
provide fundamental insight into the nature of neuronal
computation However while direct experimental evi-
dence for coordinated activity on the spike train level
mostly relies on the correlations between pairs of nerve
cells 4145 it is becoming increasingly clear that such
pairwise correlations cannot completely resolve the co-
operative dynamics of neuronal populations 31 4648
and that higher-order cumulants need to be taken into
account
One possible shortcoming of our work is the supra-
exponentially increasing complexity of the closed-form
expressions for the densities kit for higher values of
n This explosion however is mostly due to combi-
natorial factors that arise in many problems involving
cumulants As their denition naturally involves objects
such as set partitions it seems to us that these sorts of
issues would be quite dicult to avoid
Another limitation of the present model is that it only
allows for excitatory interactions - an arrival of an event
at a given time can only increase the likelihood of fu-
ture event never decrease it We hope in the future
to be able to extend our analysis to include models in
which there also exists a possibility of mutual inhibition
between points of dierent types
Further generalizations of our results might involve
computing cumulants and other important statistics
of a non-linear Hawkes processes see eg
22 for the
denition whose conditional rate function involves a
non-linear transformation of equation 6 thus allowing
for for example multiplicative interaction between point
events 49 However in this case the resulting process
no longer admits an immigrant-ospring representation
meaning an alternative approach would be necessary
V DISCUSSION
In this paper we described the method for computing
a class of statistics of linear Hawkes self-exciting point
processes with arbitrary interaction kernels By using the
Poisson cluster process representation we were able to
obtain a general procedure for deriving formulas for nth
order cumulant densities Furthermore we have shown
there is a one-to-one correspondence between the integral
terms appearing in said densities and all topologically
distinct rooted trees with n labeled leaves
We also considered the problem of computing time-
integrated cumulants and showed this can be done by
ACKNOWLEDGMENTS
Supported by the Erasmus Mundus Joint Doctoral pro-
gramme EuroSPIN and the German Federal Ministry of
Education and Research BFNT - FreiburgTubingen
grant 01GQ0830 Stojan Jovanovic acknowledges the
hospitality of NORDITA The authors would also like
to thank the referees for many helpful comments and
suggestions Marcel Sauerbier for useful discussion and
Gunnar Grah for making Figure 1
Appendix A PROOF OF EQUATION 24
Let t be an arbitrary time vector t  t1  tn and
From 5 for every vector t  t1  tn and multi-
i an arbitrary multi-index i  i1  in
index i  i1  in we have that
cid104dN i1 t1 dN in tncid105  PEi
t  Pk there is a type ik event at tk
Furthermore it is clear that
where the rst sum goes over all possible numbers of
dierent clusters that events t could be partitioned in
while tr denotes the subset of t that belong to the rth
cluster Br and ir denotes their types
Now note that the previous equation is in fact a sum
over all partitions  of the set 1  n with at least two
  1 Let us now x one such partition
blocks ie
  B1  B As   1 we must have r
1  r   that Br  n But then by the inductive
assumption
 Brir
  kir tr
and therefore
t  C i
cid88
cid89
1
kir trdtr
Finally from 56 66 and 18 we get
kir trdtr  PEi
t  C i
t  PEi
t  C i
cid88
cid89
1
t  PEi
t  C i
t denotes the complement of the set
t  PEi
t  C i
where C i
t   cluster C such that k tk  C
Indeed events t of type i either are or arent all in
some cluster C We now proceed by induction in n For
n  2 we have
cid88
t1t2  PEij
t1t2  C ij
t1t2  PEij
t1t2  C ij
But as the only way that two events are not in the
same cluster is if they each belong to a dierent one say
if t1  C and t2  D
t2  C i
t1t2  C ij
cid88
t1t2 
 C i
t2  cid104dN i
t2  Dj
cid105cid104dN j
t2cid105
t2 59
because of independence of dierent clusters C and D
t1t2  C ij
t1t2  PEij
t1t2  cid104dN it1cid105cid104dN jt2cid105
 kijt1 t2dt1dt2
proving that formula 24 is true for n  2
Next we assume that 24 is true for n  1 and prove
that it then must also be true for n
Consider the complementary set C i
t If events t are not
all in the same cluster how could they be distributed
One possibility is that they are divided up between two
dierent clusters like in the previous case In fact they
could potentially be distributed in c dierent clusters
where 2  c  n Therefore
t  C i
 Brir
ncid88
ccid89
which completes the proof
Appendix B FORMULAS FOR INTEGRATED
CUMULANTS
Let T m
i be the set of all rooted trees with root m and
leaves i  i1  in Next let T  T m
and let IT be
the corresponding integral term In order to compute the
Laplace transform LIT  we rst consider the leaves of
Each leaf ik contributes a term Rikjv
tkv for some in-
ternal node v For simplicity let us assume that leaves
i1  isv all descend from a single internal node which
we denote v Then applying to IT the Laplace transform
with respect to variables t1  tsv we obtain
svcid89
LlRiljv
tlve
vv 
where we denote v cid80sv
l1 l
Of course in general the leaves i1  in are divided
into several groups according to which internal node
they descend from In that case applying to each such
group the Laplace transform in the already described
way yields several terms of type 68
Moving one level up in tree T  we are now in a situ-
ation in which several internal nodes each with its own
group of dependent leaves all descend from a common
node u residing one level above them We denote these
internal nodes by v1  vru Each such internal node
vl contributes to IT a term jvl ju
exponential term in 68
vlu Transforming the
vlvl  e
vluvl e
uvl 
of tree T  at which point we are left with a product
of various terms of types 68 and 70 integrated with
respect to the position x of the root m as this is the last
node we reach by climbing up T  The exponential
terms in this product can be combined to form
and multiplying with jvl ju
vlu we get
rucid89
where u cid80ru
l1 vl 
vlu e
uu 
By induction we can now see that this procedure must
end after a nite number of steps equal to the depth
cid90
xcid80n
i1 idx  1    n
the integral representation of a Dirac delta function
By setting   0 we now see that the formulas for ki
can be obtained from formulas for the cumulant densities
by simply erasing all the integral signs and replacing all
the functional terms with their integrated counterparts
1 A G Hawkes Biometrika 58 83 1971
2 Y Ogata Journal of the American Statistical Associa-
062807 2014
21 A Dassios and H Zhao Advances in Applied Probability
tion 83 9 1988
43 814 2011
3 D Vere-Jones Journal of the Royal Statistical Society
22 P Bremaud and L Massoulie The Annals of Probability
Series B Methodological 32 pp 1 1970
24 pp 1563 1996
4 T Pechacek V Karas and B Czerny Astronomy and
Astrophysics 487 815 2008
23 L Zhu Journal of Applied Probability  760 2012
24 L Zhu arXiv preprint arXiv11082431  1 2011
5 P Reynaud-Bouret and S Schbath The Annals of Statis-
arXivarXiv11082431v2
tics 38 2781 2010 arXivarXiv09032919v4
25 M Bartlett Journal of the Royal Statistical Society Se-
6 L Mitchell and M E Cates Journal of Physics A Math-
ries B Methodological  264 1963
7 D Karabash
ematical and Theoretical 43 045101 2010
preprint
arXiv12114039v2  1 2012 arXivarXiv12114039v2
8 L Zhu Insurance Mathematics and Economics  1
26 A G Hawkes Journal of the Royal Statistical Society
Series B Methodological  438 1971
27 L Adamopoulos Journal of Applied Probability 12 78
1975
2013 arXivarXiv13041940v2
9 S Azizpour and K Giesecke Management Science  1
2008
10 E Errais K Giesecke and L R Goldberg SIAM Jour-
nal on Financial Mathematics 1 642 2010
11 E Bacry and J Muzy arXiv preprint arXiv14010903 
1 2014 arXivarXiv14010903v1
28 A Saichev T Maillart and D Sornette The European
Physical Journal B 86 124 2013 101140epjbe2013-
30493-9
29 A Saichev and D Sornette The European Physical Jour-
nal B-Condensed Matter and Complex Systems 83 271
2011
30 C Rossant S Leijon A K Magnusson and R Brette
12 L Bauwens and N Hautsch Modelling nancial high fre-
The Journal of Neuroscience 31 17193 2011
quency data using point processes Springer 2009
31 A Kuhn A Aertsen and S Rotter Neural Computa-
13 E Bacry S Delattre H Marc and J-F Muzy in Acous-
tics Speech and Signal Processing ICASSP 2011 IEEE
International Conference on IEEE 2011 pp 5740
14 G O Mohler M B Short P J Brantingham F P
Schoenberg and G E Tita Journal of the American
Statistical Association 106 100 2011
15 I Mastromatteo and M Marsili Journal of Statisti-
cal Mechanics Theory and Experiment 2011 P10012
2011
tion 15 67 2003
32 A Hawkes and D Oakes Journal of Applied Probability
11 493 1974
33 D R Cox and V Isham Point processes Vol 12 CRC
Press 1980
34 V Pernice B Staude S Cardanobile and S Rotter
PLoS computational biology 7 e1002059 2011
35 J Rasmussen Methodology and Computing in Applied
Probability 15 623 2013
36 E Lukacs Characteristic Functions Grin books of
16 V Pernice B Staude S Cardanobile and S Rotter
Cognate Interest Hafner Publishing Company 1970
PLoS computational biology 7 e1002059 2011
17 T Onaga and S Shinomoto Phys Rev E 89 042817
2014
37 E Bacry K Dayri and J-F Muzy The European Phys-
ical Journal B-Condensed Matter and Complex Systems
85 1 2012
18 A Saichev and D Sornette Phys Rev E 89 012104
38 J Felsenstein Inferring Phylogenies Sinauer Associates
2014
19 A Saichev and D Sornette Phys Rev E 87 022815
2013
20 S J Hardiman and J-P Bouchaud Phys Rev E 90
Incorporated 2004
39 D O Hebb The Organization of Behavior A Neuropsy-
chological Theory new ed ed Wiley New York 1949
and A M Aertsen
40 G Gerstein P Bedenbaugh
Biomedical Engineering IEEE Transactions on 36 4
1989
25 3661 2005
46 L Martignon H Von Hassein S Grun A Aertsen and
41 C M Gray and W Singer Proceedings of the National
G Palm Biological cybernetics 73 69 1995
Academy of Sciences 86 1698 1989
47 S M Bohte H Spekreijse and P R Roelfsema Neural
42 E Vaadia I Haalman M Abeles H Bergman Y Prut
Computation 12 153 2000
H Slovin and A Aertsen Nature 373 515 1995
43 A Riehle S Grun M Diesmann and A Aertsen Sci-
ence 278 1950 1997
48 I E Ohiorhenuan F Mechler K P Purpura A M
and J D Victor Nature 466 617
Schmid Q Hu
2010
44 W Bair E Zohary and W T Newsome The journal
49 S Cardanobile and S Rotter Journal of Computational
of Neuroscience 21 1676 2001
Neuroscience 28 267 2009 arXiv09041505v3
45 A Kohn and M A Smith The Journal of neuroscience
