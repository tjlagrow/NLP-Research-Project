Memoization in Constraint Logic Programming
Mark Johnson
Brown University
Introduction
This paper shows how to apply memoization caching of subgoals and associated answer substi-
tutions in a constraint logic programming setting The research is is motivated by the desire to
apply constraint logic programming CLP to problems in natural language processing
In general logic programming provides an excellent theoretical framework for computational
linguistics 13 CLP extends standard logic programming by allowing program clauses to in-
clude constraints from a specialized contraint language For example the CLP framework allows
the feature-structure constraints that have proven useful in computational linguistics 15 to be
incorporated into logic programming in a natural way 1 5 16
Because modern linguistic theories describe natural language syntax as a system of interacting
modules which jointly determine the linguistic structures associated with an utterance 2 a
grammar can be regarded as a conjunction of constraints whose solutions are exactly the well-formed
or grammatical analyses Parsers for such grammars typically coroutine between a tree-building
component that generates nodes of the parse tree and the well-formedness constraints imposed by
the linguistic modules on these tree structures 4 6 8 Both philosophically and practically this
ts in well with the CLP approach
But the standard CLP framework inherits some of the weaknesses of the SLD resolution pro-
cedure that it is based on When used with the standard formalization of a context-free grammar
the SLD resolution procedure behaves as a recursive descent parser With left-recursive gram-
mars such parsers typically fail to terminate because a goal corresponding to a prediction of a
left-recursive category can reduce to an identical subgoal up to renaming producing an innite
loop Standard techniques for left-recursion elimination 12 13 in context-free grammars are not
always directly applicable to grammars formulated as the conjunction of several constraints 10
With memoization or the caching of intermediate goals and their corresponding answer sub-
stitutions a goal is solved only once and its solutions are cached the solutions to identical goals
are obtained from this cache Left recursion need not lead to non-termination because identical
subgoals are not evaluated and the innite loop is avoided Further memoization can sometimes
provide the advantages of dynamic programming approaches to parsing the Earley deduction proof
procedure a memoized version of SLD resolution simulates an Earley parse 3 when used with
the standard formalization of a context-free grammar 14
This paper was presented at the First Workshop on Principles and Practice of Constraint Programming April
2830 1993 Newport Rhode Island The research descrined in it was initiated during a summer visit to the IMSV
Universitat Stuttgart which I would like to thank for their support Thanks also to Pascal van Hentenryck and
Fernando Pereira for their important helpful suggestions
parseString Tree - wfTree s yTree String 
y -Word WordWords Words
y Tree1 Words0 Words - yTree1 Words0 Words
y Tree1Tree2 Words0 Words -
yTree1 Words0 Words1 yTree2 Words1 Words
wfnp-kim np
wfn-friend n
wfv-walks v
wfsTree1 Tree2 s - wfTree1 np wfTree2 vp
 S  NP VP
wfnpTree1 Tree2 np - wfTree1 np wfTree2 n  NP  NP N
wfvpTree1 vp - wfTree1 v
 NP  Kim
 VP  V
 N  friend
 V  walks
Figure 1 A grammar fragment
Thus constraint logic programming and memoization are two recent developments in logic pro-
gramming that are important for natural language processing But it is not obvious how or even if
the two can be combined in a single proof procedure For example both Earley Deduction 14 and
OLDT resolution 17 20 resolve literals in a strict left-to-right order so they are not capable of
rudimentary constraint satisfaction techniques such as goal delaying The strict left-to-right order
restriction is relaxed but not removed in 18 19 where literals can be resolved in any local order
This paper describes soundness and completeness proofs for a proof procedure that extends these
methods to allow for goal delaying In fact the lemma table proof procedure generalizes naturally
to constraint logic programming over arbitrary domains as described below
The lemma table proof procedure generalizes Earley Deduction and OLDT resolution in three
 Goals can be resolved in any order including non-local orders rather than a xed left-to-
right or a local order
 The goals entered into the table consist of non-empty sets of literals rather than just single
literals These sets can be viewed as a single program literal and zero or more constraints
that are being passed down into the subsidary proof
 The solutions recorded in the lemma table may contain unresolved goals These unresolved
goals can be thought of as constraints that are being passed out of the subsidary proof
2 A linguistic example
Consider the grammar fragment in Figure 1 cf also 4 pages 142177 The parse relation holds
between a string and a tree if the yield of the tree is the string to be parsed and tree satises a well-
formedness condition In this example the well-formedness condition is that the tree is generated
by a simple context-free grammar but in more realistic fragments the constraints are considerably
more complicated
Trees are represented by terms A tree consisting of a single pre-terminal node labelled C whose
single child is the word W is represented by the term C-W  A tree consisting of a root node labelled
C dominating the sequence of trees T1    Tn is represented by the term CT1     Tn
The predicate wfTree Cat holds if Tree represents a well-formed parse tree with a root node
labelled Cat for the context free grammar shown in the comments The predicate yTree S0 S
holds if S0S is a dierence list representing the yield of Tree it collects the terminal items in the
familiar tree-walking fashion From this program the following instances of parse can be deduced
these are meant to approximate possessive constructions like Kims friends friend walks
parsekimwalks snp-kimvpv-walks
parsekimfriendwalks snpnp-kimn-friendvpv-walks
parsekimfriendfriendwalks
snpnpnp-kimn-friendn-friendvpv-walks
The parsing problem is encoded as a goal as follows The goal consists of an atom with the
predicate parse whose rst argument instantiated to the string to be parsed and whose second
argument is uninstantiated The answer substitution binds the second argument to the parse tree
For example an answer substitution for the goal parseKimfriendwalks Tree will have the parse
tree for the string Kim friend walks as the binding for Tree
Now consider the problem of parsing using the program shown in Figure 1 Even with the vari-
able String instantiated both of the subgoals of parse taken independently have an innite number
of subsumption-incomparable answer substitutions Informally this is because there are an innite
number of trees generated by the context-free grammar and there are an innite number of trees
that have any given non-empty string as their yield Because the standard memoization techniques
mentioned above all compute all of the answer substitutions to every subgoal independently they
never terminate on such a program
However the set of answer substitions that satisfy both constraints is nite because the number
of parse trees with the same yield with respect to this grammar is nite The standard approach
to parsing with such grammars takes advantage of this by using a selection rule that coroutines
the goals wf and y delaying all wf goals until the rst argument is instantiated to a non-variable
In such a system the wf goals function as constraints that lter the trees generated by the goals y
In this example however there is a second related problem Coroutining is not sucient to
yield a nite SLD tree even though the number of refutations is nite Informally this is because
the grammar in Figure 1 is left recursive and the search space for a recursive descent parser which
an SLD refutation mimics with such a program is innite
Figure 2 shows part of an innite SLD derivation from the goal parseKW T where KW is
assumed bound to kimwalks although the binding is actually immaterial as no step in this
refutation instantiates this variable The selection rule expresses a preference for goals with
certain arguments instantiated If there is a literal of the form wfT C with T instantiated to a non-
variable then the left-most such literal is selected otherwise if there is a literal of the form yT S0 S
with S0 instantiated to a non-variable then the left-most such literal is selected otherwise the left-
most literal is selected The selected literal is underlined and the new literals introduced by each
reduction are inserted to the left of the old literals
Note that the y and wf literals resolved at steps 6 and 7 in Figure 2 are both children
1 parseKWT
2 wfTs yTKW
3 wf T1T2s yT1KWS1 yT2S1
4 wfT1np wfT2vp yT1KWS1   
5 yT3KWS3 yT4S3S1 wf T3T4np   
6 wfT3np wfT4n yT3KWS3   
7 yT5KWS5 yT6S5S3 wf T5T6np   
Figure 2 An innite SLD refutation despite co-routining
of and variants of the literals resolved at steps 5 and 6 This sequence of resolution steps
can be iterated an arbitrary number of times
It is a manifestation of the left recursion in the
well-formedness constraint wf
One standard technique for dealing with such left-recursion is memoization 14 13 But there
are two related problems in applying the standard logic programming memoization techniques to
this problem
First because the standard methods memoize and evaluate at the level of an individual literal
the granularity at which they apply memoization is is to small As noted above in general individual
wf or y literal can have an innite number of answer substitutions The lemma table proof procedure
circumvents this problem by memoizing conjunctions of literals in this example a conjunction of
wf and y literals which has only a nite number of subsumption-incomparable valid instances
The second problem is that the standard memoization techniques restrict the order in which
literals can be resolved
In general these restrictions prevent the goal delaying required to
co-routine among several constraints The lemma table proof procedure lifts this restriction by
allowing arbitrary selection rules
3 The Lemma Table proof procedure
Like the Earley Deduction and the OLDT proof procedures the Lemma Table proof procedure
maintains a lemma table that records goals and their corresponding solutions After a goal has
been entered into the lemma table other occurences of instances of that goal can be reduced by
the solutions from the lemma table instead of the original program clauses
We now turn to a formal presentation of the Lemma Table proof procedure In what follows
lower-case letters are used for variables that range over atoms Upper-case letters are used for
variables that range over goals which are sets of atoms Goals are interpreted conjunctively a goal
is satised i all of its members are
A goal G subsumes a goal G i there is some substitution  such that G  G Note that
mgus for sets of goals are in general not unique even up to renaming
The informational units manipulated by the lemma table proof procedure are called general-
ized clauses A generalized clause is a pair of goals and is written G1  G2 G1 is called the head
of the clause and G2 is called the body Both the head and body are interpreted conjunctively ie
G1  G2 should be read as if each of the G2 are true then all of the G1 are true A generalized
clause has a natural interpretation as a goal subject to constraints G1 is true in any interpretation
which satises the constraints expressed by G2
A lemma table is a set of table entries of the form hG T Si where
1 G is a goal this entry is called a table entry for G
2 T is a lemma tree see below and
3 S is a sequence of clauses called the solution list for this entry
A lemma tree is a tree constructed by the algorithm described below Its nodes have two labels
These are
1 a clause A  B called the clause labelling of the node and
2 an optional tag which when present is one of solution programb for some b  B or
tableB  p where   B   B and p is either the null pointer nil or a pointer into a so-
lution list of a table entry for some G that subsumes B 
Untagged nodes are nodes that have not yet been processed All nodes are untagged when they
are created and they are assigned a tag as they are processed The tags indicate which kind of
resolution has been applied to this clause A node tagged programb is resolved against the clauses
dening b in the program A node tagged tableB  p is resolved against the instances of a table
entry E for some goal that subsumes B  the pointer p keeps track of how many of the solutions
from E have been inserted under this node just as in OLDT resolution Finally a node tagged
solution is not resolved rather its clause labelling is added to the solution list for this table entry
Just as SLD resolution is controlled by a selection rule that determines which literal will be
reduced next the Lemma Table proof procedure is controlled by a control rule R which determines
the next goal if any to be reduced and the manner of its reduction
More precisely R must tag a node with clause labelling A  B with a tag that is either solution
programb for some b  B or tableB  nil such that   B   B Further R must tag the root
node of every lemma tree with the tag programb for some b this ensures that some program
reductions are performed in every lemma tree and hence that a lemma table entry cannot be used
to reduce itself vacuously
Finally as in OLDT resolution the Lemma Table proof procedure allows a user-specied ab-
straction operation  that maps goals to goals such that G subsumes G for all goals G This
is used to generalize the goals in the same way as the term-depth abstraction operation in OLDT
resolution which it generalizes
The Lemma Table proof procedure can now be presented
Input A non-empty goal G a program P  an abstraction operation  and a control rule R
Output A set  of clauses of the form G  C where G is an instance of G
Algorithm Create a lemma table with one table entry hG T i where T contains a single un-
tagged node with the clause labelling G  G Then repeat the following operations until no
operation applies Finally return the solution list from the table entry for G
The operations are as follows
Prediction Let v be an untagged node in a lemma tree T of table entry hG T Si and let
vs clause labelling be A  B Apply the rule R to v and perform the action specied
below depending on the form of the tag R assigned to v
solution  Add A  B to the end of the solution list S
programb  Let B   B  b Then for each clause b  C in P such that b and b
unify with a mgu  create an untagged child node v of v labelled A  B   C
tableB  nil  The action in this case depends on whether there already is a table entry
hG T  S i for some G that subsumes B  If there is set the pointer in the tag to
the start of the sequence S  If there is not create a new table entry hB  T  i
where T  contains a single untagged node with clause labelling B   B  Set
the pointer in vs tag to point to the empty solution list of this new table entry
Completion Let v be a node with clause labelling A  B and tagged tableB  p such that
p points to a non-null portion S  of a solution list of some table entry Then advance
p over the rst element B   C of S  to point to the remainder of S  Further if
B  and B  unify with mgu  then add a new untagged child node to v labelled
A  B  B   C
It may help to consider an example based on the program in Figure 1 The computation
rule R used is the following Let v be a node in a lemma tree and let A  B be its clause
If v is the root of a lemma tree and B contains a literal of the form yT S0 S then
Rv  programyT S0 S
If B is empty then Rv  solution no other tagging is pos-
If B contains a literal of the form wfT C where T is a non-variable
sible for such nodes
then Rv  programwfT C there is never more than one such literal Otherwise if B
contains two literals of the form wfT C yT S0 S where S0 is a non-variable then Rv 
tablewfT C yT S0 S nil These four cases exhaust all of the node labelling encountered in
the example1
Figure 3 depicts the completed lemma table constructed using the rule R for the goal wfTrees
yTreekimwalks To save space kim and walks are abbreviated to k and w respectively Only
the tree from each table entry is shown because the other components of the entry can be read
o the tree The goal of each table entry is the head of the clause labelling its root clause and is
shown in bold face Solution nodes are shown in italic face Lookup nodes appear with a dashed
line pointing to the table entry used to reduce them
The rst few steps of the proof procedure are the following each step corresponds to the circled
node of the same number
1 The root node of the rst table entrys tree restates the goal to be proven Informally this node
searches for an S located at the beginning of the utterance The literal yTreekimwalks is
selected for program reduction This reduction produces two child nodes one of which dies
in the next step because there are no matching program nodes
2 The reduction 1 partially instantiates the parse tree Tree The literal wfCT1T2 is
selected for program reduction
1 When used with a program encoding a context-free grammars in the manner of Figure 1 the Lemma Table
proof procedure with the control rule R simulates Earleys CFG parsing algorithm 3 The operations in the Lemma
Table proof procedure are named after the corresponding operations of Earleys algorithm
wfTrees yTreekw  wfTrees yTreekw
wfCT1s yCT1kw 
    wfCT1s yT1kw
wfCT1T2s yCT1T2kw 
     wfCT1T2s yT1kwS1 yT2S1
wfsT1T2s ysT1T2kw 
     wfT1np wfT2vp yT1kwS1 yT2S1
wfsnp-kimT2s ysnp-kimT2kw 
    wfT2vp yT2w
wfsnp-kvpv-ws ysnp-kvpv-wkw  
wfTnp yTkwS   wfTnp yTkwS
wfC-knp yC-kkww 
    wfC-knp
wfnp-knp ynp-kkww  
wfCT1np yCT1kwS 
    wfCT1np yT1kwS
wfCT1T2np yCT1T2kwS 
    wfCT1T2np yT1kwS1 yT2S1S
wfnpT1T2np ynpT1T2kwS 
    wfT1np wfT2n yT1kwS1 yT2S1S
wfnpnp-kT2np ynpnp-kT2np 
    wfT2n yT2wS
wfTn yTwS   wfTn yTwS
wfC-wn yC-ww 
    wfC-wn
wfCT1T2n yCT1T2wS 
    wfCT1T2n yT1wS1 yT2S1S
wfCT1n yCT1wS 
    wfCT1n yT1wS
wfTvp yTwS   wfTvp yTwS
wfC-wvp yC-ww 
    wfC-wvp
wfCT1T2vp yCT1T2wS 
    wfCT1T2vp yT1wS1 yT2S1S
wfCT1vp yCT1wS 
    wfCT1vp yT1wS
wfvpT1vp yvpT1wS 
    wfT1v yT1wS
wfvpv-wvp yvpv-ww  
wfTv yTwS   wfTv yTwS
wfC-wv yC-ww 
    wfC-wv
wfv-wv yv-ww  
wfCT1T2v yCT1T2wS 
    wfCT1T2v yT1wS1 yT2S1S
wfCT1v yCT1wS 
    wfCT1v yT1wS
Figure 3 A lemma table for wfTrees yTreekimwalks
3 This produces a clause body that contains literals that refer to the subtree T1 and literals
that refer to the subtree T2 The computation rule in eect partitions the literals and selects
those that refer to the subtree T1 because they are associated with an instantiated left string
argument
4 A new table entry is created for the literals selected in 3 Informally this entry searches for
an NP located at the beginning of the utterance Because this node is a root node the literal
yTkimwalksS is selected for program expansion
56 The literals with predicate wf are selected for program expansion
7 The body of this nodes clause label is empty so its label is added to the solutions list of the
table entry Informally this node corresponds to the string kim having been recognized as
8 The solution found in 7 is incorporated into the tree beneath 3 A new table entry is
generated to search for a VP spanning the string walks
9 Just as in 3 the literals in the body of this clauses label refer to two distinct subtrees and
as before the computation rule selects the literals that refer to T1 However there is already a
table entry 4 for the selected goal so a new table entry is not created The solutions already
found for 4 generate a child node to search for an N beginning at walks No solutions are
found for this search
4 Soundness and Completeness
This section demonstrates the soundness and completness of the lemma table proof procedure
Soundness is straight-forward but completeness is more complex to prove The completeness proof
relies on the notion of an unfolding of a lemma tree in which the table nodes of a lemma tree are
systematically replaced with the tree that they point to In the limit the resulting tree can be
viewed a kind of SLD proof tree and completeness follows from the completeness of SLD resolution
Theorem 1 Soundness If the output of lemma table proof procedure contains a clause G  C
then P  C  G
Proof Each of the clause labels on lemma tree nodes is either a tautology or derived by resolving
other clause labels and program clauses Soundness follows by induction on the number of steps
taken by the proof procedure
As might be expected the completeness proof is much longer than the soundness proof For
space reasons it is only sketched here
For the completeness proof we assume that the control rule R is such that the output  of
the lemma table proof procedure contains only clauses with empty bodies This is reasonable
in the current context because non-empty clause bodies correspond to goals that have not been
completely reduced
Then completeness follows if for all P  G and  if P  G then there is an instance G on the
solution list that subsumes G
Further without loss of generality the abstraction operation  is assumed to be the identity
function on goals since if Gt  Gt the goal Gt can be replaced with the equivalent
Gt  t  t and  taken to be the identity function
Now it is a corollary of the Switching Lemma 11 pages 4547 that if P  G then there is an
n such that for any computation rule there is an SLD refutation of G of length n whose computed
answer substitution  subsumes  We show that if  is a computed answer substitution for an
SLD derivation of length n then there is a node tagged solution and labelled G   in lemma tree
T for the top-level goal
First a well-formedness condition on lemma trees is introduced Every lemma tree in a lemma
table at the termination of the lemma table proof procedure is well-formed Well-formedness and
the set of nodes tagged solution are preserved under an abstract operation on lemma trees called
expansion The expansion of a lemma tree is the tree obtained by replacing each node tagged
tableB  p with the lemma tree in the table entry pointed to by p
Because expansions preserves well-formedness the lemma tree T  resulting from n iterated
expansions of the lemma tree T for the top-level goal is also well-formed Moreover since the root
node of every lemma tree is required to be tagged program all nodes in T  within distance n arcs of
the root will be tagged program or solution This top part of T  is isomorphic to the top part of an
SLD tree Ts for G so if  is a computed answer substitution for an SLD derivation in Ts of length
n or less then there is a node tagged solution and labelled G   in T  and hence T  Since n was
arbitrary every SLD refutation in Ts has a corresponding node tagged solution in T  and hence in
5 Conclusion
This paper generalizes standard memoization techniques for logic programming to allow them to
be used for constraint logic programming The basic informational unit used in the Lemma Table
proof procedure is the generalized clause G  C Generalized clauses can be given a constraint
interpretation as any interpretation which satises the constraints C also satises G The lemmas
recorded in the lemma table state how sets of literals are reduced to other sets of literals Because
the heads of the lemmas consist of sets of literals rather than just individual literals the lemmas
express properties of systems of constraints rather than just individual constraints Because the
solutions recorded in the lemma table can contain unresolved constraints it is possible to pass
constraints out of a lemma into the superordinate computation
In this paper G and C were taken to be sets of literals and the constraints C were dened by
Horn clauses In a more general setting both G and C would be permitted to contain constraints
drawn from a specialized constraint language not dened by a Horn clause program Hohfeld
and Smolka 5 show how to extend SLD resolution to allow general constraints over arbitrary
domains Their elegant relational approach seems to be straight-forwardly applicable to the Lemma
Table proof procedure and would actually simplify its theoretical description because equality and
unication would be treated in the constraint system Unication failure would then be a special
case of constraint unsatisability and would be handled by the optimization described by Hofeld
and Smolka that permits nodes labelled with clauses G  C to be deleted if C is unsatisable
References
1 Chen W and DS Warren 1989 C-Logic of Complex Objects ms Department of Computer
Science State University of New York at Stony Brook
2 Chomsky N 1986 Knowledge of Language Its nature origins and use Praeger New York
3 Earley J 1970 An ecient context-free parsing algorithm in Comm ACM 132 pages 94
4 Giannesini F H Kanoiui R Pasero and M van Canegham 1986 Prolog Addison-Wesley
Reading Massachusetts
5 Hohfeld M and G Smolka 1988 Denite Relations over Constraint Languages Lilog re-
port 53 IBM Deutschland
6 Johnson M 1989 The Use of Knowledge of Language in Journal of Psycholinguistic Re-
search 181
7 Johnson M 1990 Features frames and quantier-free formulae in P Saint-Dizier and S
Szpakowicz eds Logic and Logic Grammars for Language Processing Ellis Horwood New
York pages 94107
8 Johnson M 1991 Deductive Parsing The Use of Knowledge of Language in RC Berwick
SP Abney and C Tenny eds Principle-based Parsing Computational and Psycholinguistics
Kluwer Academic Publishers Dordrecht pages 3965
9 Johnson M 1991 Techniques for deductive parsing in CG Brown and G Koch eds
Natural Language and Logic Programming III North Holland Amsterdam pages 2742
10 Johnson M 1992 The left-corner program transformation ms Brown University
11 Lloyd J 1984 Foundations of Logic Programming Springer-Verlag Berlin
12 Matsumoto M H Tanaka H Hirakawa H Miyoshi and H Yasukawa 1983 BUP a bottom-
up parser embedded in Prolog in New Generation Computing 12 pages 145158
13 Pereira F and S Shieber 1987 Prolog and Natural Language Analysis CSLI Lecture Notes
Series Chicago University Press
14 Pereira F and DH Warren 1983 Parsing as Deduction in Proceedings of the 21st Annual
Meeting of the Association for Computational Linguistics MIT Cambridge Mass
15 Shieber S 1985 Introduction to Unication-based theories of Grammar CLSI Lecture Notes
Series Chicago University Press
16 Smolka G 1992 Feature Constraint Logics for Unication Grammars in The Journal of
Logic Programming 121-2 pages 5187
17 Tamaki H and T Sato 1986 OLDT resolution with tabulation in Proceedings of Third
International Conference on Logic Programming Springer-Verlag Berlin pages 8498
18 Vieille L 1987 Database-complete proof procedures based on SLD resolution in Logic
Programming Proceedings of the fourth international conference The MIT Press Cambridge
Massachusetts
19 Vieille L 1989 Recursive query processing
the power of logic Theoretical Computer
Science 69 pages 153
20 Warren D S 1992 Memoing for logic programs in Communications of the ACM 353
pages 94111
