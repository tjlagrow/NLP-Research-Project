Evaluation of Computational Grammar Formalisms for Indian Languages 
Nisheeth Joshi 1 Iti Mathur 2 
1 2 Department of Computer Science Apaji Institute Banasthali University Rajasthan India 
nisheethjoshirediffmailcom 1 mathuritirediffmailcom 2 
their  systems 
initially  stared  with  a 
Due  to  this  reason  NLP  researchers  in  order  to 
tried  a  new 
improve  performance  of 
approach  They 
rule  based 
traditional approach This was called the seed data Once 
this  was  done  it  was  then  supplied  to  machine  learning 
techniques  This approach  was termed  as hybrid approach 
partially  rule based and partially statistical  We  can find 
evidence of improved systems in literature which used this 
approach23 This approach even helped in development 
of  probabilistic  parsers  like  Stanford  parser4  Charniak 
parser5  MaltParser6 These all  parsers  where  supplied 
with different computational grammars formalisms or with 
treebanks  which  were  developed  using  manually  parsed 
sentences  based  on  one  of  the  formalisms  for  example 
Penn  Treebank7  TIGER  Treebank8 
Paraguay 
Dependency  Treebank9  In  one  or 
the  other  way 
grammar  formalisms  were  used  for  development  of  deep 
parsers  In this paper we attempt to study the performance 
of  some  of  the  popular  computational grammar formalism 
techniques  which  could  be  used  in  development  of  deep 
language  processing  applications 
like  a  deep  parser 
machine translators semantic role labeler etc 
dependency 
The  motivation  for  this  study  came from  the  fact  that 
free  word  order  is  one  of  the  areas  were  grammar 
formalism  has not yet reached  the  level of  good accuracy 
In  this  area  there  have  been  numerous  claims  to  prove 
superiority 
formalisms1011  But  often  discussions  based  on  this 
formalism  ignore  more  practical  aspects  like  usability  and 
expressivity  In order to examine free word order approach 
we  conducted  our  study  on  Hindi  Since  all  other  Indian 
languages  follow  the  same  phenomena  The  approach 
suggested in this study can be applied to other languages 
grammar 
2 COMPUTATIONAL GRAMMAR FORMALISMS 
In  general  computational  grammars  can  be  divided  into 
three  categories  based  on  their  functionality  They  are 
Phrase  Structure  Grammars  Dependency  Grammars  and 
Hybrid  Grammars  A  phrase structure grammar is the one 
which  uses 
transformational 
the  approach  shown  by 
ABSTRACT 
Natural  Language  Parsing  has  been  the  most  prominent 
research  area  since  the  genesis  of  Natural  Language 
Processing  Probabilistic  Parsers  are  being  developed  to 
make  the  process  of  parser  development  much  easier 
accurate and fast In Indian context identification of which 
Computational Grammar Formalism is to be used is still a 
question  which  needs  to  be  answered  In  this  paper  we 
focus  on 
to  analyze  different 
formalisms for Indian languages 
this  problem  and 
Index  Terms  Indian  Languages  Computational 
Grammars  Linguistic  Theories  Syntactic  Structures 
Evaluation1 
1 INTRODUCTION 
Natural Language Parsing has been an important activity in 
Natural  Language  Processing  NLP  development  But 
even since the introduction of machine learning techniques 
into  NLP  application  development  the  scenario  changed 
drastically  This  new  approach  appeared 
to  be  very 
promising  as  it  helped  in rapid  prototype  development  of 
NLP  systems In  this  technique  large amount of data was 
used  onto  which  various  models  like  Hidden  Markov 
Model HMM Conditional Random Fields CRF Neural 
Networks NN Support Vector Machines SVM etc were 
applied  These  approaches  are  also  termed  as  statistical 
approaches  or  Statistical  Natural  Language  Processing 
SNLP  This  was  a  very  effective  way  of  application 
development  with applications attaining 60-75 accuracy 
with  very  little  effort  Unfortunately  this  approach  soon 
lost its shine as after a point of optimized performance they 
become very less helpful in improvement of the systems1 
Moreover it failed to implement broad coverage parsing or 
deep parsing 
                                        
Proc of International Conference in Computer Engineering 
and  Technology  2012  Organized  by  Jodhpur  Institute  of 
Engineering and Technology Jodhpur Sponsored by IEEE 
USA and Institution of Engineers India Kolkatta 
        
grammars where specific tree positions are associated with 
assignments of various syntactic roles such as subject and 
object  This concept is the motivation for having elements 
appear  in  various  positions  in  the  tree  in  the  process  of 
deriving  the  final  syntactic structure Some  of the popular 
formalisms  of  this  category  are  Tree  Adjoining  Grammar 
TAG  12  Head  Driven  Phrase  Structure  HPSG  13 
Grammar  Hybrid  grammar  augments  phrase  structure 
grammar  by  expressing  non-projective  syntactic  relations 
while  maintaining  a  more  formally  defined  architecture 
then  phrase  structure  grammar  Lexical  Functional 
Grammar LFG14 is an example of hybrid grammar 
A dependency grammar consists of a set of words and a 
set of directed binary dependency relations between words 
such that  
  No words depends on itself 
  Each dependent has one and only one head 
  A head may have many dependents 
  There  is  one  distinguished word  which is the head  of 
the sentence and depends on no other word 
  All other words in a sentence are dependents such that 
the whole sentence is connected 
Dependency  grammars  have  been 
studied  by 
Gaifman15 who studied linear precedence in dependency 
relations  Hudson16  who  introduced  word  grammar 
Starosta  17  who studied  lexicase  grammar and Bharti  et 
al18  who  showed  the  similarities  between  Paninian 
Grammar 
suitability of PG in Indian context 
PG  and  dependency  grammar  and 
3 METHODOLODY 
In  order  to  understand  the  pros  and  corns  of  different 
grammar  formalism we tested all  three types of grammar 
formalisms From phrase structure stable we selected TAG 
LFG from hybrid and PG from dependency framework 
for  all 
We  developed  parallel  grammars 
frameworks  and  took  a  detailed  note  of  development 
process and variations in syntactic structures We recorded 
time taken to construct each sentence the total time taken 
to  complete  the  task  and  the  average  time  taken  for  the 
task  We  also  noted  the  difficulty  level  with  which  each 
grammar was developed 
Since  all  three  grammar  formalism  are  somewhat 
distinct in nature it was very much necessary to develop a 
mechanism  which  would  not  be  biased  towards  one 
grammar  and  penalize  others  To  ensure  the  equivalence 
we  tested  each  grammar  using  the  same  set  of  sentences 
test  case  contained  grammatical  as  well  as 
ungrammatical  sentences  Each  grammar  was  required  to 
distinguish  between  the  two  categories  Moreover  each 
grammar was required to provide predicate arguments and 
modifiers for each sentence which was parsed Figure 1 and 
2  give  a  brief  idea  of  the  type  of  sentences  used  Various 
types of sentences used in the test case were 
  Basic sentences with auxiliary verbs 
  Sentences having case assigning post positions 
  Sentences marking subjects 
  Adpositional sentences 
  Sentences with generative constructions 
  Sentences with descriptive adjectives 
  Sentences with predicative adjectives 
  Sentences with relativeco-relative constructions 
a  cid551        
ladkii ne  ladke ko   mara 
girl-Erg   boy-Acc   hit 
b   cid551     
mara ladkii ne ladke ko 
c     cid551   
ladke ko ladkii ne mara 
d      cid551  
mara ladke ko ladkii ne 
e      cid551  
ladke ko mara ladkii ne 
f  cid551      
ladkii ne mara ladke ko 
Figure 1 Simple Hindi Test Sentence with various variations 19 
a                         cid551      
jo     khari       hai  vo          ladkii  lambii hai 
Rel   standing  be   Co-Rel  girl      tall     is  
b   cid551      
jo ladkii khari hai vo lambii hai 
c   cid551      
vo ladkii khari hai jo lambii hai 
d    cid551    cid551   
vo ladkii lambi hai jo ladkii khari hai 
e       cid551   
vo lambi hai jo ladkii khari hai  
f   cid551      
vo ladkii jo khari hai lambii hai 
g     cid551     
vo jo ladkii khari hai lambii hai 
Figure 2 Simple Hindi Test Sentence with various variations 19 
LFG and DG had no problems to handle these type of 
sentences We used Lexicalized TAG LTAG which is the 
modification of TAG and can handle word order variation  
We  did  this  study  using  ten  grammar  writes  which 
were  provided  with  the  sentences  and  were  asked  to 
construct  the  grammars  for  each  sentence  In  order  to 
understand  the  usability  of  each  grammar  we  provided 
each  writer  with  35  sentences  from  various  categories  as 
discussed  above  Each  writer  was  provided  with  a  short 
tutorial  of  each  grammar  Shortly  after  the  tutorial  of  a 
particular  grammar  the  writers  were  asked  to  implement 
the sentences for the said grammar Their performance was 
calculated on the measure discussed above 
Writer 
Average  103 
Table 1 Total Time Taken and Accuracy Achieved by Each 
Grammar Writer 
Table 2 Highest Voted Ranks by Grammar Writers for each 
grammar 
Basic Sentences 
Auxiliary Verbs 
Case Assigning PPs 
Adpositional Sentences 
Descriptive Adjectives 
Genitive Case 
Predictive Adjectives 
Relative Clause 
Difficulty 
4 RESULTS 
We calculated the results for total and average time taken to 
complete  the  task  accuracy  with  which  the  task  was 
completed  difficulty  ratings  provided  by  each  writer  for 
each  formalism  on  different  categories  of  sentences  The 
types  of  errors  committed  The  results  of  the  study  are 
provided in the following sections 
41 Time Taken and Accuracy 
Table 1 summarizes the average time taken to complete the 
task by each writer and the accuracy with which they did it 
Looking  at  the  data  it  is  clearly  seen  that  time  taken  to 
complete the task was least in PG and most in LFG TAG 
was in between the two  
The average time taken by the writers to complete the 
task for PG TAG and LFG is 103 min 34 min and 56 min 
respectively  PG  took  least  time  with  which  the  sentences 
were  completed  We  also  measured  average  accuracy  of 
each writer Here TAG scored more accuracy then the other 
formalisms 
42 Difficulty Rating 
After the task we provided the questionnaire to the writers 
We asked them to provide us with the difficulty rating for 
each type of sentence for each grammar We asked them to 
ranks the difficulty of sentences between 1 and 5 where 1 
being  the  easiest  and  5  being  the  toughest  As  it  was  not 
possible to provide results for all the writes here In Table 
2 we provide the ranks given majority of writers The sores 
without brackets are the ranks given and the ones in bracket 
are the no of writers who gave this rank  
We  can  see  that  PG  sores  very  well  in  simple 
generative  and  predictive  adjective  cases  but  do  not 
perform well on other categories of the sentences TAG on 
the other hand performs moderately well It sores highest in 
four categories of sentences LFG scores highest in just one 
43 Error Analysis 
We  also  examined  the  types  of  errors  committed  by 
different formalisms as we wanted to know why writer had 
great difficulty with LFG as compared to PG or TAG  
In  Paninian Grammar we analyzed that writers faced 
great  difficulty  in  assigning  relationships  to  dependency 
structures This could be due to the notational convention of 
the formalism or due to the difficulty with the concepts of 
head  and  dependents  We  also  saw  that  whenever  a 
directional error was made the correct rule was framed for 
the  dependency  This  shows 
implementing 
difficulty  was  with  the  notion  and  not  with  the  concepts 
Moreover PG although being least rigorous out of the three 
showed  some  sluggishness  while  dealing  with  complex 
sentences 
In  Tree Adjoining Grammar  we saw that most errors 
were  in  the  formation  of  the  derived  trees  Between 
adjunction and substitution operations adjunction proved to 
be more error prone Almost 80 errors were made due to 
incorrect adjunction operation This shows that writers had 
great difficulty understanding the adjunction operation  
In Lexical Functional Grammar we saw that grammar 
writers  had  great  difficulty  in  associating  features  with 
constituent  structures  In  some  cases  the  writers  got 
confused  as  to  use  noun  phrase  and  verb  phrase  in 
constituent  structure  or  to  use  subject  and  predicate  in 
feature  structure  Although  this  formalism  is  the  most 
perfect  in terms of  linguistic phenomena  as it captures all 
the  aspects  of  the  languages  grammar  it  is  also  fairly 
difficulty  to  understand  as  it  takes  time  for  the  grammar 
write to understand and implement grammar using it 
5 CONCLUSION 
We wanted to study the applicability of different grammar 
formalism on Indian languages so that different NLP tasks 
like  development  of  a  deep  probabilistic  parser  or 
development of a Treebank could be under taken In doing 
so we  gathered insights into the different formalisms  and 
understood the merits and demerits of each 
We  found  out  that  though  Paninain  Grammar  was 
preferred for simple sentences overall performance of TAG 
was good It scored better in the average accuracy attained 
to write the sentences Although this is a preliminary study 
and  more in-depth  evaluations are required before making 
any  sound  conclusions  But  with some confidence we can 
say  that  TAG  can  perform  better  in  most  of  the  difficult 
cases as compared to dependency grammar 
6 REFERENCES 
Project 
JG  Neal EL  Feit and CA  Montgomery Benchmark 
InvestigationIdentification 
Machine 
Translation Springer Germany Vol 8 No 1-2 pp77-84 
T Baldwin J  Beavers EM  Bender D Flickinger A 
Kim and S Oepen Beauty and the beast What running 
a broad-coverage precision grammar over thee bnc taught 
us  about  the  grammar    and  the  corpus  Linguistic 
Evidence  Empirical  Theoretical  and  Computational 
Perspectives  Mouton  de  Gruyter  Berlin  Germany  pp 
4970 2005 
S  A  Waterman  Distributed  parse  mining 
Proceedings  of  the  NAACL  Workshop  on  Software 
Engineering Testing and Quality Assurance for Natural 
Language Processing USA 2009 
CD Manning and H Schtze Foundations of Statistical 
Natural Language Processing MIT Press USA 1999 
E Charniak  A Maximum  Entropy Inspired Parser In 
Proceedings of NAACL USA 2000 
J  Nivre  J  Hall  and  J  Nilsson  MaltParser  A  Data-
Driven  Parser-Generator 
for  Dependency  Parsing 
In Proceedings  of  the  fifth  international  conference  on 
Language  Resources  and  Evaluation  Genoa  Italy  pp 
2216-2219 May 2006  
A  Taylor  A  Warner  and  B  Santorini  The  Penn 
Treebank An Overview Treebanks Building and Using 
Parsed  Corpora  Kluwer  Academic 
Publishers 
Netherlands 2003 
S Brants S Dipper P Eisenberg S Hansen E Knig 
W  Lezius  C  Rohrer  G  Smith  and  H  Uszkoreit 
TIGER  Linguistic  interpretation of  a  German corpus 
Research  on  Language  and  Computation  Springer 
Germany Vol 9 No 2 pp 597-620 2004 
J  Haji  B  Hladk  and  P  Pajas    The  Prague 
Dependency  Treebank  Annotation  Structure 
Support  In  Proceedings  of  the  IRCS  Workshop  on 
Linguistic  Databases  Pennsylvania  USA  pp  105-114 
10  M  Covington  Parsing  Discontinuous  Constituents 
Dependency  in  Dependency  Grammar  Computational 
Linguistics MIT Press USA Vol 16 No 4 pp-234-236 
11  R Sangal and V Chaitanya An Intermediate Language 
for Machine Translation An approach based on Sanskrit 
using  conceptual  graph  notation  Journal  of  Computer 
Society of India Mumbai India Vol 17 pp 9-21 1987 
to  Tree  Adjoining 
 AK  Joshi  An 
Grammars Mathematics of Language John Benjamins 
Netherlands 1987  
IA Sag T Wasow and EM Bender Syntactic Theory 
2 Edition CSLI Publications USA 2001 
Introduction 
14  M Dalrymple Lexical Functional Grammar Syntax and 
Semantics Academic Press USA 2001 
15  H  Gaifman  Dependency systems  and  phrase  structure 
systems Information and Control USA Vol 8 pp 304-
337 1965 
J Hudson Word Grammar Basil Blackwell England 
S  Starosta  The  Case  for  Lexicase  An  Outline  of 
Lexicase Grammatical Theory Cassell London 1988 
18  A  Bharti  V  Chaitanya  R  Sangal  Natural  Language 
Processing A Paninian Perspective PHI India 1999 
19  V  Dwivedi  Tropicalization 
Correlative  Construction  Theoretical  Perspectives  on 
Word  Order 
in  South  Asian  Languages  CSLI 
Publications USA 1994 
in  Hindi  and 
Evaluation of Computational Grammar Formalisms for Indian Languages 
Nisheeth Joshi 1 Iti Mathur 2 
1 2 Department of Computer Science Apaji Institute Banasthali University Rajasthan India 
nisheethjoshirediffmailcom 1 mathuritirediffmailcom 2 
their  systems 
initially  stared  with  a 
Due  to  this  reason  NLP  researchers  in  order  to 
tried  a  new 
improve  performance  of 
approach  They 
rule  based 
traditional approach This was called the seed data Once 
this  was  done  it  was  then  supplied  to  machine  learning 
techniques  This approach  was termed  as hybrid approach 
partially  rule based and partially statistical  We  can find 
evidence of improved systems in literature which used this 
approach23 This approach even helped in development 
of  probabilistic  parsers  like  Stanford  parser4  Charniak 
parser5  MaltParser6 These all  parsers  where  supplied 
with different computational grammars formalisms or with 
treebanks  which  were  developed  using  manually  parsed 
sentences  based  on  one  of  the  formalisms  for  example 
Penn  Treebank7  TIGER  Treebank8 
Paraguay 
Dependency  Treebank9  In  one  or 
the  other  way 
grammar  formalisms  were  used  for  development  of  deep 
parsers  In this paper we attempt to study the performance 
of  some  of  the  popular  computational grammar formalism 
techniques  which  could  be  used  in  development  of  deep 
language  processing  applications 
like  a  deep  parser 
machine translators semantic role labeler etc 
dependency 
The  motivation  for  this  study  came from  the  fact  that 
free  word  order  is  one  of  the  areas  were  grammar 
formalism  has not yet reached  the  level of  good accuracy 
In  this  area  there  have  been  numerous  claims  to  prove 
superiority 
formalisms1011  But  often  discussions  based  on  this 
formalism  ignore  more  practical  aspects  like  usability  and 
expressivity  In order to examine free word order approach 
we  conducted  our  study  on  Hindi  Since  all  other  Indian 
languages  follow  the  same  phenomena  The  approach 
suggested in this study can be applied to other languages 
grammar 
2 COMPUTATIONAL GRAMMAR FORMALISMS 
In  general  computational  grammars  can  be  divided  into 
three  categories  based  on  their  functionality  They  are 
Phrase  Structure  Grammars  Dependency  Grammars  and 
Hybrid  Grammars  A  phrase structure grammar is the one 
which  uses 
transformational 
the  approach  shown  by 
ABSTRACT 
Natural  Language  Parsing  has  been  the  most  prominent 
research  area  since  the  genesis  of  Natural  Language 
Processing  Probabilistic  Parsers  are  being  developed  to 
make  the  process  of  parser  development  much  easier 
accurate and fast In Indian context identification of which 
Computational Grammar Formalism is to be used is still a 
question  which  needs  to  be  answered  In  this  paper  we 
focus  on 
to  analyze  different 
formalisms for Indian languages 
this  problem  and 
Index  Terms  Indian  Languages  Computational 
Grammars  Linguistic  Theories  Syntactic  Structures 
Evaluation1 
1 INTRODUCTION 
Natural Language Parsing has been an important activity in 
Natural  Language  Processing  NLP  development  But 
even since the introduction of machine learning techniques 
into  NLP  application  development  the  scenario  changed 
drastically  This  new  approach  appeared 
to  be  very 
promising  as  it  helped  in rapid  prototype  development  of 
NLP  systems In  this  technique  large amount of data was 
used  onto  which  various  models  like  Hidden  Markov 
Model HMM Conditional Random Fields CRF Neural 
Networks NN Support Vector Machines SVM etc were 
applied  These  approaches  are  also  termed  as  statistical 
approaches  or  Statistical  Natural  Language  Processing 
SNLP  This  was  a  very  effective  way  of  application 
development  with applications attaining 60-75 accuracy 
with  very  little  effort  Unfortunately  this  approach  soon 
lost its shine as after a point of optimized performance they 
become very less helpful in improvement of the systems1 
Moreover it failed to implement broad coverage parsing or 
deep parsing 
                                        
Proc of International Conference in Computer Engineering 
and  Technology  2012  Organized  by  Jodhpur  Institute  of 
Engineering and Technology Jodhpur Sponsored by IEEE 
USA and Institution of Engineers India Kolkatta 
        
grammars where specific tree positions are associated with 
assignments of various syntactic roles such as subject and 
object  This concept is the motivation for having elements 
appear  in  various  positions  in  the  tree  in  the  process  of 
deriving  the  final  syntactic structure Some  of the popular 
formalisms  of  this  category  are  Tree  Adjoining  Grammar 
TAG  12  Head  Driven  Phrase  Structure  HPSG  13 
Grammar  Hybrid  grammar  augments  phrase  structure 
grammar  by  expressing  non-projective  syntactic  relations 
while  maintaining  a  more  formally  defined  architecture 
then  phrase  structure  grammar  Lexical  Functional 
Grammar LFG14 is an example of hybrid grammar 
A dependency grammar consists of a set of words and a 
set of directed binary dependency relations between words 
such that  
  No words depends on itself 
  Each dependent has one and only one head 
  A head may have many dependents 
  There  is  one  distinguished word  which is the head  of 
the sentence and depends on no other word 
  All other words in a sentence are dependents such that 
the whole sentence is connected 
Dependency  grammars  have  been 
studied  by 
Gaifman15 who studied linear precedence in dependency 
relations  Hudson16  who  introduced  word  grammar 
Starosta  17  who studied  lexicase  grammar and Bharti  et 
al18  who  showed  the  similarities  between  Paninian 
Grammar 
suitability of PG in Indian context 
PG  and  dependency  grammar  and 
3 METHODOLODY 
In  order  to  understand  the  pros  and  corns  of  different 
grammar  formalism we tested all  three types of grammar 
formalisms From phrase structure stable we selected TAG 
LFG from hybrid and PG from dependency framework 
for  all 
We  developed  parallel  grammars 
frameworks  and  took  a  detailed  note  of  development 
process and variations in syntactic structures We recorded 
time taken to construct each sentence the total time taken 
to  complete  the  task  and  the  average  time  taken  for  the 
task  We  also  noted  the  difficulty  level  with  which  each 
grammar was developed 
Since  all  three  grammar  formalism  are  somewhat 
distinct in nature it was very much necessary to develop a 
mechanism  which  would  not  be  biased  towards  one 
grammar  and  penalize  others  To  ensure  the  equivalence 
we  tested  each  grammar  using  the  same  set  of  sentences 
test  case  contained  grammatical  as  well  as 
ungrammatical  sentences  Each  grammar  was  required  to 
distinguish  between  the  two  categories  Moreover  each 
grammar was required to provide predicate arguments and 
modifiers for each sentence which was parsed Figure 1 and 
2  give  a  brief  idea  of  the  type  of  sentences  used  Various 
types of sentences used in the test case were 
  Basic sentences with auxiliary verbs 
  Sentences having case assigning post positions 
  Sentences marking subjects 
  Adpositional sentences 
  Sentences with generative constructions 
  Sentences with descriptive adjectives 
  Sentences with predicative adjectives 
  Sentences with relativeco-relative constructions 
a  cid551        
ladkii ne  ladke ko   mara 
girl-Erg   boy-Acc   hit 
b   cid551     
mara ladkii ne ladke ko 
c     cid551   
ladke ko ladkii ne mara 
d      cid551  
mara ladke ko ladkii ne 
e      cid551  
ladke ko mara ladkii ne 
f  cid551      
ladkii ne mara ladke ko 
Figure 1 Simple Hindi Test Sentence with various variations 19 
a                         cid551      
jo     khari       hai  vo          ladkii  lambii hai 
Rel   standing  be   Co-Rel  girl      tall     is  
b   cid551      
jo ladkii khari hai vo lambii hai 
c   cid551      
vo ladkii khari hai jo lambii hai 
d    cid551    cid551   
vo ladkii lambi hai jo ladkii khari hai 
e       cid551   
vo lambi hai jo ladkii khari hai  
f   cid551      
vo ladkii jo khari hai lambii hai 
g     cid551     
vo jo ladkii khari hai lambii hai 
Figure 2 Simple Hindi Test Sentence with various variations 19 
LFG and DG had no problems to handle these type of 
sentences We used Lexicalized TAG LTAG which is the 
modification of TAG and can handle word order variation  
We  did  this  study  using  ten  grammar  writes  which 
were  provided  with  the  sentences  and  were  asked  to 
construct  the  grammars  for  each  sentence  In  order  to 
understand  the  usability  of  each  grammar  we  provided 
each  writer  with  35  sentences  from  various  categories  as 
discussed  above  Each  writer  was  provided  with  a  short 
tutorial  of  each  grammar  Shortly  after  the  tutorial  of  a 
particular  grammar  the  writers  were  asked  to  implement 
the sentences for the said grammar Their performance was 
calculated on the measure discussed above 
Writer 
Average  103 
Table 1 Total Time Taken and Accuracy Achieved by Each 
Grammar Writer 
Table 2 Highest Voted Ranks by Grammar Writers for each 
grammar 
Basic Sentences 
Auxiliary Verbs 
Case Assigning PPs 
Adpositional Sentences 
Descriptive Adjectives 
Genitive Case 
Predictive Adjectives 
Relative Clause 
Difficulty 
4 RESULTS 
We calculated the results for total and average time taken to 
complete  the  task  accuracy  with  which  the  task  was 
completed  difficulty  ratings  provided  by  each  writer  for 
each  formalism  on  different  categories  of  sentences  The 
types  of  errors  committed  The  results  of  the  study  are 
provided in the following sections 
41 Time Taken and Accuracy 
Table 1 summarizes the average time taken to complete the 
task by each writer and the accuracy with which they did it 
Looking  at  the  data  it  is  clearly  seen  that  time  taken  to 
complete the task was least in PG and most in LFG TAG 
was in between the two  
The average time taken by the writers to complete the 
task for PG TAG and LFG is 103 min 34 min and 56 min 
respectively  PG  took  least  time  with  which  the  sentences 
were  completed  We  also  measured  average  accuracy  of 
each writer Here TAG scored more accuracy then the other 
formalisms 
42 Difficulty Rating 
After the task we provided the questionnaire to the writers 
We asked them to provide us with the difficulty rating for 
each type of sentence for each grammar We asked them to 
ranks the difficulty of sentences between 1 and 5 where 1 
being  the  easiest  and  5  being  the  toughest  As  it  was  not 
possible to provide results for all the writes here In Table 
2 we provide the ranks given majority of writers The sores 
without brackets are the ranks given and the ones in bracket 
are the no of writers who gave this rank  
We  can  see  that  PG  sores  very  well  in  simple 
generative  and  predictive  adjective  cases  but  do  not 
perform well on other categories of the sentences TAG on 
the other hand performs moderately well It sores highest in 
four categories of sentences LFG scores highest in just one 
43 Error Analysis 
We  also  examined  the  types  of  errors  committed  by 
different formalisms as we wanted to know why writer had 
great difficulty with LFG as compared to PG or TAG  
In  Paninian Grammar we analyzed that writers faced 
great  difficulty  in  assigning  relationships  to  dependency 
structures This could be due to the notational convention of 
the formalism or due to the difficulty with the concepts of 
head  and  dependents  We  also  saw  that  whenever  a 
directional error was made the correct rule was framed for 
the  dependency  This  shows 
implementing 
difficulty  was  with  the  notion  and  not  with  the  concepts 
Moreover PG although being least rigorous out of the three 
showed  some  sluggishness  while  dealing  with  complex 
sentences 
In  Tree Adjoining Grammar  we saw that most errors 
were  in  the  formation  of  the  derived  trees  Between 
adjunction and substitution operations adjunction proved to 
be more error prone Almost 80 errors were made due to 
incorrect adjunction operation This shows that writers had 
great difficulty understanding the adjunction operation  
In Lexical Functional Grammar we saw that grammar 
writers  had  great  difficulty  in  associating  features  with 
constituent  structures  In  some  cases  the  writers  got 
confused  as  to  use  noun  phrase  and  verb  phrase  in 
constituent  structure  or  to  use  subject  and  predicate  in 
feature  structure  Although  this  formalism  is  the  most 
perfect  in terms of  linguistic phenomena  as it captures all 
the  aspects  of  the  languages  grammar  it  is  also  fairly 
difficulty  to  understand  as  it  takes  time  for  the  grammar 
write to understand and implement grammar using it 
5 CONCLUSION 
We wanted to study the applicability of different grammar 
formalism on Indian languages so that different NLP tasks 
like  development  of  a  deep  probabilistic  parser  or 
development of a Treebank could be under taken In doing 
so we  gathered insights into the different formalisms  and 
understood the merits and demerits of each 
We  found  out  that  though  Paninain  Grammar  was 
preferred for simple sentences overall performance of TAG 
was good It scored better in the average accuracy attained 
to write the sentences Although this is a preliminary study 
and  more in-depth  evaluations are required before making 
any  sound  conclusions  But  with some confidence we can 
say  that  TAG  can  perform  better  in  most  of  the  difficult 
cases as compared to dependency grammar 
6 REFERENCES 
Project 
JG  Neal EL  Feit and CA  Montgomery Benchmark 
InvestigationIdentification 
Machine 
Translation Springer Germany Vol 8 No 1-2 pp77-84 
T Baldwin J  Beavers EM  Bender D Flickinger A 
Kim and S Oepen Beauty and the beast What running 
a broad-coverage precision grammar over thee bnc taught 
us  about  the  grammar    and  the  corpus  Linguistic 
Evidence  Empirical  Theoretical  and  Computational 
Perspectives  Mouton  de  Gruyter  Berlin  Germany  pp 
4970 2005 
S  A  Waterman  Distributed  parse  mining 
Proceedings  of  the  NAACL  Workshop  on  Software 
Engineering Testing and Quality Assurance for Natural 
Language Processing USA 2009 
CD Manning and H Schtze Foundations of Statistical 
Natural Language Processing MIT Press USA 1999 
E Charniak  A Maximum  Entropy Inspired Parser In 
Proceedings of NAACL USA 2000 
J  Nivre  J  Hall  and  J  Nilsson  MaltParser  A  Data-
Driven  Parser-Generator 
for  Dependency  Parsing 
In Proceedings  of  the  fifth  international  conference  on 
Language  Resources  and  Evaluation  Genoa  Italy  pp 
2216-2219 May 2006  
A  Taylor  A  Warner  and  B  Santorini  The  Penn 
Treebank An Overview Treebanks Building and Using 
Parsed  Corpora  Kluwer  Academic 
Publishers 
Netherlands 2003 
S Brants S Dipper P Eisenberg S Hansen E Knig 
W  Lezius  C  Rohrer  G  Smith  and  H  Uszkoreit 
TIGER  Linguistic  interpretation of  a  German corpus 
Research  on  Language  and  Computation  Springer 
Germany Vol 9 No 2 pp 597-620 2004 
J  Haji  B  Hladk  and  P  Pajas    The  Prague 
Dependency  Treebank  Annotation  Structure 
Support  In  Proceedings  of  the  IRCS  Workshop  on 
Linguistic  Databases  Pennsylvania  USA  pp  105-114 
10  M  Covington  Parsing  Discontinuous  Constituents 
Dependency  in  Dependency  Grammar  Computational 
Linguistics MIT Press USA Vol 16 No 4 pp-234-236 
11  R Sangal and V Chaitanya An Intermediate Language 
for Machine Translation An approach based on Sanskrit 
using  conceptual  graph  notation  Journal  of  Computer 
Society of India Mumbai India Vol 17 pp 9-21 1987 
to  Tree  Adjoining 
 AK  Joshi  An 
Grammars Mathematics of Language John Benjamins 
Netherlands 1987  
IA Sag T Wasow and EM Bender Syntactic Theory 
2 Edition CSLI Publications USA 2001 
Introduction 
14  M Dalrymple Lexical Functional Grammar Syntax and 
Semantics Academic Press USA 2001 
15  H  Gaifman  Dependency systems  and  phrase  structure 
systems Information and Control USA Vol 8 pp 304-
337 1965 
J Hudson Word Grammar Basil Blackwell England 
S  Starosta  The  Case  for  Lexicase  An  Outline  of 
Lexicase Grammatical Theory Cassell London 1988 
18  A  Bharti  V  Chaitanya  R  Sangal  Natural  Language 
Processing A Paninian Perspective PHI India 1999 
19  V  Dwivedi  Tropicalization 
Correlative  Construction  Theoretical  Perspectives  on 
Word  Order 
in  South  Asian  Languages  CSLI 
Publications USA 1994 
in  Hindi  and 
