Hawkes Processes
Patrick J Laub  Thomas Taimre  Philip K Pollett
Last edited July 13 2015
Abstract Hawkes processes are a particularly interesting class of stochastic process that have been
applied in diverse areas from earthquake modelling to nancial analysis They are point processes
whose dening characteristic is that they self-excite meaning that each arrival increases the rate of
future arrivals for some period of time Hawkes processes are well established particularly within the
nancial literature yet many of the treatments are inaccessible to one not acquainted with the topic
This survey provides background introduces the eld and historical developments and touches upon
all major aspects of Hawkes processes
1 Introduction
Events that are observed in time frequently cluster natually An earthquake typically increases the
geological tension in the region where it occurs and aftershocks likely follow 1 A ght between rival
gangs can ignite a spate of criminal retaliations 2 Selling a signicant quantity of a stock could
precipitate a trading urry or on a larger scale the collapse of a Wall Street investment bank could
send shockwaves through the worlds nancial centres 3
The Hawkes process HP is a mathematical model for these self-exciting processes named after
its creator Alan G Hawkes 4 The HP is a counting process that models a sequence of arrivals of
some type over time for example earthquakes gang violence trade orders or bank defaults Each
arrival excites the process in the sense that the chance of a subsequent arrival is increased for some
time period after the initial arrival As such it is a non-Markovian extension of the Poisson process
Some datasets such as the number of companies defaulting on loans each year 5 suggest that the
underlying process is indeed self exciting Furthermore using the basic Poisson process to model say
the arrival of trade orders of a stock is highly inappropriate because participants in equity markets
exhibit a herding behaviour a standard example of economic reexivity 6
The process of generating model tting and testing the goodness of t of HPs is examined in
this survey As the HP literature in nancial elds is particularly well developed applications in these
areas are considered chiey here
P J Laub
Department of Mathematics The University of Queensland Qld 4072 Australia and
Department of Mathematics Aarhus University Ny Munkegade DK-8000 Aarhus C Denmark
E-mail plaubuqeduaumathaudk
T Taimre
Department of Mathematics The University of Queensland Qld 4072 Australia
E-mail ttaimreuqeduau
P K Pollett
Department of Mathematics The University of Queensland Qld 4072 Australia
E-mail pkpmathsuqeduau
Patrick J Laub et al
Fig 1 An example point process realisation t1 t2    and corresponding counting process N t
2 Background
Before discussing HPs some key concepts must be elucidated Firstly we briey give denitions for
counting processes and point processes thereby setting essential notation Secondly we discuss the
lesser-known conditional intensity function and compensator both core concepts for a clear under-
standing of HPs
21 Counting and point processes
We begin with the denition of a counting process
Denition 1 Counting process A counting process is a stochastic process N t  t  0 taking
values in N0 that satises N 0  0 is almost surely as nite and is a right-continuous step
function with increments of size 1 Further denote by Hu  u  0 the history of the arrivals up
to time u Strictly speaking H is a ltration that is an increasing sequence of -algebras
A counting process can be viewed as a cumulative count of the number of arrivals into a system
up to the current time Another way to characterise such a process is to consider the sequence of
random arrival times T  T1 T2    at which the counting process N  has jumped The process
dened as these arrival times is called a point process described in Denition 2 adapted from 7
see Fig 1 for an example point process and its associated counting process
Denition 2 Point process If a sequence of random variables T  T1 T2    taking values in
0 has P0  T1  T2       1 and the number of points in a bounded region is as nite then
T is a simple point process
The counting and point process terminology is often interchangeable For example if one refers to
a Poisson process or a HP then the reader must infer from the context whether the counting process
N  or the point process of times T is being discussed
t1t2t3t4t5t6t7Ntt1234567Hawkes Processes
One way to characterise a particular point process is to specify the distribution function of the
next arrival time conditional on the past Given the history up until the last arrival u Hu dene
as per 8 the conditional cdf and pdf of the next arrival time Tk1 as
cid90 t
cid90 t
kcid89
tHu 
PTk1  s s  dsHu ds 
sHu ds 
The joint pdf for a realisation t1 t2     tk is then by the chain rule
f t1 t2     tk 
ti Hti1 
In the literature the notation rarely species H explicitly but rather a superscript asterisk is
used see for example 9 We follow this convention and abbreviate F tHu and ftHu to
F t and ft respectively
Remark 1 The function ft can be used to classify certain classes of point processes For example
if a point process has an ft which is independent of Ht then the process is a renewal process
22 Conditional intensity functions
Often it is dicult to work with the conditional arrival distribution ft Instead another characteri-
sation of point processes is used the conditional intensity function Indeed if the conditional intensity
function exists it uniquely characterises the nite-dimensional distributions of the point process see
Proposition 72IV of 9 Originally this function was called the hazard function 10 and was dened
ft
1  F t
Although this denition is valid we prefer an intuitive representation of the conditional intensity
function as the expected rate of arrivals conditioned on Ht
Denition 3 Conditional intensity function Consider a counting process N  with associated
histories H If a non-negative function t exists such that
t  lim
EN t  h  N tHt
which only relies on information of N  in the past that is t is Ht-measurable then it is called
the conditional intensity function of N 
The terms self-exciting and self-regulating can be made precise by using the conditional intensity
function If an arrival causes the conditional intensity function to increase then the process is said to
be self-exciting This behaviour causes temporal clustering of T  In this setting t must be chosen to
avoid explosion where we use the standard denition of explosion as the event that N t  N s  
for t  s   See Fig 2 for an example realisation of such a t
Alternatively if the conditional intensity function drops after an arrival the process is called self-
regulating and the arrival times appear quite temporally regular Such processes are not examined
hereafter though an illustrative example would be the arrival of speeding tickets to a driver over time
assuming each arrival causes a period of heightened caution when driving
Patrick J Laub et al
Fig 2 An example conditional intensity function for a self-exciting process
23 Compensators
Frequently the integrated conditional intensity function is needed for example in parameter estima-
tion and goodness of t testing it is dened as follows
Denition 4 Compensator For a counting process N  the non-decreasing function
cid90 t
t 
is called the compensator of the counting process
In fact a compensator is usually dened more generally and exists even when  does not exist
Technically t is the unique Ht predictable function with 0  0 and is non-decreasing such
that N t  M t  t almost surely for t  0 and where M t is an Ht local martingale whose
existence is guaranteed by the DoobMeyer decomposition theorem However for HPs  always
exists in fact as we shall see in Section 3 a HP is dened in terms of this function and therefore
Denition 4 is sucient for our purposes
3 Literature review
With essential background and core concepts outlined in Section 2 we now turn to discussing HPs
including their useful immigrationbirth representation We briey touch on generalisations before
turning to a illustrative account of HPs for nancial applications
31 The Hawkes process
Point processes gained a signicant amount of attention in the eld of statistics during the 1950s and
1960s First Cox 10 introduced the notion of a doubly stochastic Poisson process now called the Cox
process and Bartlett 11 12 13 investigated statistical methods for point processes based on their
power spectral densities At IBM Research Laboratories Lewis 14 formulated a point process model
for computer failure patterns which was a step in the direction of the HP The activity culminated in
the signicant monograph by Cox and Lewis 15 on time series analysis modern researchers appreciate
ttt1t2t3t4t5t6t7Hawkes Processes
this text as an important development of point process theory since it canvassed their wide range of
applications 9 p 16
It was in this context that Hawkes 4 set out to bring Bartletts spectral analysis approach to a
new type of process a self-exciting point process The process Hawkes described was a one-dimensional
point process though originally specied for t  R as opposed to t  0 and is dened as follows
Denition 5 Hawkes process Consider N t  t  0 a counting process with associated history
Ht  t  0 that satises
PN t  h  N t  mHt 
t h  oh 
1  t h  oh  m  0
cid90 t
Suppose the process conditional intensity function is of the form
t  u dN u
t   
for some   0 and   0  0 which are called the background intensity and excitation function
respectively Assume that  cid54 0 to avoid the trivial case that is a homogeneous Poisson process
Such a process N  is a Hawkes process
Remark 2 The denition above has t as non-negative however an alternative form of the HP is to
consider arrivals for t  R and set N t as the number of arrivals in 0 t Typically HP results hold
for both denitions though we will specify that this second t  R denition is to be used when it is
required
Fig 3 a A typical Hawkes process realisation N t and its associated t in b both plotted
against their expected values
Remark 3 In modern terminology Denition 5 describes a linear HPthe nonlinear version is given
later in Denition 6 Unless otherwise qualied the HPs in this paper will refer to this linear form
A realisation of a HP is shown in Fig 3 with the associated path of the conditional intensity
process Hawkes 16 soon extended this single point process into a collection of self- and mutually-
exciting point processes which we will turn to discussing after elaborating upon this one-dimensional
process
0102030405060708090100020406080100tCountNtENt01020304050607080901000123tIntensitytEt6
Patrick J Laub et al
32 Hawkes conditional intensity function
The form of the Hawkes conditional intensity function in 3 is consistent with the literature though
it somewhat obscures the intuition behind it Using t1 t2     tk to denote the observed sequence of
past arrival times of the point process up to time t the Hawkes conditional intensity is
t   
t  ti 
cid88
The structure of this  is quite exible and only requires specication of the background intensity
  0 and the excitation function  A common choice for the excitation function is one of expo-
nential decay Hawkes 4 originally used this form as it simplied his theoretical derivations 17 In
this case t   et which is parameterised by constants    0 and hence
t   
ts dN s   
tti 
cid90 t
cid90 t
cid88
cid88
The constants  and  have the following interpretation each arrival in the system instantaneously
increases the arrival intensity by  then over time this arrivals inuence decays at rate 
Another frequent choice for  is a power law function giving
t   
c  t  sp dN s   
c  t  tip
with some positive scalars c k and p The power law form was popularised by the geological model
called Omoris law used to predict the rate of aftershocks caused by an earthquake 18 More com-
putationally ecient than either of these excitation functions is a piecewise linear function as in
19 However the remaining discussion will focus on the exponential form of the excitation function
sometimes referred to as the HP with exponentially decaying intensity
One can consider the impact of setting an initial condition 0  0 perhaps in order to model
a process from some time after it is started In this scenario the conditional intensity process using
the exponential form of  satises the stochastic dierential equation
t  0 
t    
t dt   dN t 
cid90 t
Applying stochastic calculus yields the general solution of
t  e
t0     
ets dN s 
t  0 
which is a natural extension of 4 20
33 Immigrationbirth representation
Stability properties of the HP are often simpler to divine if it is viewed as a branching process
Imagine counting the population in a country where people arrive either via immigration or by birth
Say that the stream of immigrants to the country form a homogeneous Poisson process at rate 
Each individual then produces zero or more children independently of one another and the arrival of
births form an inhomogeneous Poisson process
Hawkes Processes
Fig 4 Hawkes process represented as a collection of family trees immigrationbirth representation
Squares cid4 indicate immigrants circles cid32 are ospringdescendants and the crosses  denote
the generated point process
An illustration of this interpretation can be seen in Fig 4 In branching theory terminology this
immigrationbirth representation describes a GaltonWatson process with a modied time dimension
Hawkes 21 used the representation to derive asymptotic characteristics of the process such as the
following result
Theorem 1 Hawkes process asymptotic normality If
cid90 
0  n 
s ds  1 and
ss ds  
cid90 
cid33
then the number of HP arrivals in 0 t is asymptotically t   normally distributed More precisely
writing N 0 t  N t  N 0
cid32
N 0 t  t1  n
cid112t1  n3
 y 
where  is the cdf of the standard normal distribution
Remark 4 More modern work uses the immigrationbirth representation for applying Bayesian tech-
niques see for example 22
For an individual who enters the system at time ti  R the rate at which they produce ospring
at future times t  ti is t  ti Say that the direct ospring of this individual comprise the rst-
generation and their ospring comprise the second-generation and so on members of the union of all
these generations are called the descendants of this ti arrival
Using the notation from 23 Section 54 dene Zi to be the random number of ospring in the ith
generation with Z0  1 As the rst-generation ospring arrived from a Poisson process Z1  Poin
where the mean n is known as the branching ratio This branching ratio which can take values in
0 is dened in Theorem 1 and in the case of an exponentially decaying intensity is
cid90 
s ds 
Knowledge of the branching ratio can inform development of simulation algorithms For each
immigrant i the times of the rst-generation ospring arrivalsconditioned on knowing the total
number of them Z1are each iid with density t tin Section 6 explores HP simulation methods
inspired by the immigrationbirth representation in more detail
Patrick J Laub et al
The value of n also determines whether or not the HP explodes To see this let gt  Et
A renewal-type equation will be constructed for g and then its limiting value will be determined
Conditioning on the time of the rst jump
gt  Ecid2
tcid3  E
cid34
cid90 t
cid35
cid90 t
t  s dN s
t  s EdN s 
In order to calculate this expected value start with
s  lim
EN s  h  N sHs
EdN sHs
and take expectations and apply the tower property
gs  E
EEdN sHs
EdN s
to see that
Therefore
cid90 t
gt   
EdN s  gs ds 
cid90 t
t  s gs ds   
gt  s s ds 
This renewaltype equation in convolution notation is g    g cid63  then has dierent solutions
according to the value of n Asmussen 24 splits the cases into the defective case n  1 the proper
case n  1 and the excessive case n  1 Asmussens Proposition 74 states that for the defective
gt  E
t  
as t   
However in the excessive case t   exponentially quickly and hence N  eventually explodes
Explosion for n  1 is supported by viewing the arrivals as a branching process Since EZi  ni
1  n
see Section 54 Lemma 2 of 23 the expected number of descendants for one individual is
 cid88
 
cid88
cid40 n
cid88
EZi 
1n  n  1
n  1
Therefore n  1 means that one immigrant would generate innitely many descendants on average
When n  0 1 the branching ratio can be interpreted as a probability It is the ratio of the
number of descendants for one immigrant to the size of their entire family all descendants plus the
original immigrant that is
Ecid2cid80
1  Ecid2cid80
cid3
cid3 
Therefore any HP arrival selected at random was generated endogenously a child with probability
wp n or exogenously an immigrant wp 1 n Most properties of the HP rely on the process being
stationary which is another way to insist that n  0 1 a rigorous denition is given in Section 34
so this is assumed hereinafter
Hawkes Processes
34 Covariance and power spectral densities
HPs originated from the spectral analysis of general stationary point processes The HP is stationary
for nite values of t when it is dened as per Remark 2 so we will use this denition for the remainder
of Subsection 34 Finding the power spectral density of the HP gives access to many techniques
from the spectral analysis eld for example model tting can be achieved by using the observed
periodogram of a realisation The power spectral density is dened in terms of the covariance density
Once again the exposition is simplied by using the shorthand that
dN t  lim
N t  h  N t 
Unfortunately the term stationary has many dierent meanings in probability theory In this
context the HP is stationary when the jump process dN t  t  0which takes values in 0 1is
weakly stationary This means that EdN t and CovdN t dN ts do not depend on t Stationarity
in this sense does not imply stationarity of N  or stationarity of the inter-arrival times 25 One
consequence of stationarity is that  will have a long term mean as given by 6
  E
EdN t
1  n
The autocovariance density is dened for   0 to be
cid18 dN t
cid19
R   Cov
dN t   
Due to the symmetry of covariance R   R  however R cannot be extended to the whole of R
because there is an atom at 0 For simple point processes EdN t2  EdN t since dN t  0 1
therefore for   0
EdN t2  EdN t   dt 
The complete covariance density complete in that its domain is all of R is dened as
Rc      R 
where  is the Dirac delta function
Remark 5 Typically R0 is dened such that Rc is everywhere continuous Lewis 25 p 357
states that strictly speaking Rc does not have a value at   0 See 12 15 and 4 for further
details
The corresponding power spectral density function is then
cid90 
S 
i Rc  d 
cid34
cid90 
 
cid35
i R  d
Up to now the discussion excluding the nal value of 7 has considered general stationary point
processes To apply the theory specically to HPs we need the following result
Patrick J Laub et al
Theorem 2 Hawkes process power spectral density Consider a HP with an exponentially decaying
intensity with    The intensity process then has covariance density for   0
Hence its power spectral density is    R
R  
2  
2  2 e
 
S 
2  
2  
  2  2
Proof Adapted from 4 Consider the covariance density for   R  0
R   E
dN t   
 2
Firstly note that via the tower property
cid20 dN t
dN t   
cid18
cid20 dN t
cid34
cid34
cid20 dN t
cid21
cid20 dN t
cid19
cid21
cid21cid35
cid21cid35
cid12cid12cid12Ht   
cid12cid12cid12Ht   
dN t   
cid20 dN t   
cid21
t   
Hence 10 can be combined with 3 to see that R  equals
cid32
 dN t
cid90 t
t    s dN s
cid33  2
which yields
R     
   
cid90 
cid90 
  vRv dv
  vRv dv 
cid90 
  vRv dv 
Refer to Appendix A1 for details this is a WienerHopf-type integral equation Taking the Laplace
transform of 11 gives
Refer to Appendix A2 for details Note that 5 and 7 supply      which implies that
Lcid8R cid9 s 
Lcid8R cid9 s 
cid26
2  
2  s    
2  
2  2s    
cid27
Therefore
R   L 1
2  
2  2s    
2  
2  2 e
 
Hawkes Processes
The values of  and Lcid8R cid9 s are then substituted into the denition given in 9
cid35
 
i R  d
cid90 
cid90 
cid34
cid20
cid104
  Lcid8R cid9 i  Lcid8R cid9 i
cid34
i R  d 
cid90 
 
2  
cid105
 
ei R  d
cid21
2  
2  i    
2  i    
cid35
cid20
2  
2  
  2  2
cid21
S 
Remark 6 The power spectral density appearing in Theorem 2 is a shifted scaled Cauchy pdf
Remark 7 As R is a real-valued symmetric function its Fourier transform S is also real-valued
and symmetric that is
cid34
cid90 
cid35
cid34
cid90 
 
i R  d
 
cos R  d
cid35
S 
S  S  S  2S 
It is common that S is plotted instead of S as in Section 45 of 15 this is equivalent to
wrapping the negative frequencies over to the positive half-line
35 Generalisations
The immigrationbirth representation is useful both theoretically and practically However it can only
be used to describe linear HPs Bremaud and Massoulie 26 generalised the HP to its nonlinear form
Denition 6 Nonlinear Hawkes process Consider a counting process with conditional intensity
function of the form
cid32cid90 t
t  
t  s N ds
cid33
where   R  0   0  R Then N  is a nonlinear Hawkes process Selecting  x    x
reduces N  to the linear HP of Denition 5
Modern work on nonlinear HPs is much rarer than the original linear case for simulation see
pp 96116 of 7 and associated theory in 27 This is due to a combination of factors rstly the
generalisation was introduced relatively recently and secondly the increased complexity frustrates
even simple investigations
Now to return to the extension mentioned earlier that of a collection of self- and mutually-exciting
HPs The processes being examined are collections of one-dimensional HPs which excite themselves
and each other
Patrick J Laub et al
Denition 7 Mutually exciting Hawkes process Consider a collection of m counting processes
N1     Nm denoted N  Say Tij  i  1     m j  N are the random arrival times for each
counting process and tij for observed arrivals If for each i  1     m then Ni has conditional
intensity of the form
i t  i 
jt  u dNju
cid90 t
mcid88
for some i  0 and i  0  0 then N is called a mutually exciting Hawkes process
When the excitation functions are set to be exponentially decaying 12 can be written as
i t  i 
ij ts dNjs  i 
ij ttjk
cid90 t
mcid88
mcid88
cid88
for non-negative constants ij  ij  i j  1     m
Remark 8 There are models for HPs where the points themselves are multi-dimensional for example
spatial HPs or temporo-spatial HPs 2 One should not confuse mutually exciting HPs with these
multi-dimensional HPs
36 Financial applications
This section reviews primarily the work of At-Sahalia et al 28 and Filimonov and Sornette 6
It assumes the reader is familiar with mathematical nance and the use of stochastic dierential
equations
361 Financial contagion
We turn our attention to the moest recent applications of HPs A major domain for self- and mutually-
exciting processes is nancial analysis Frequently it is seen that large movements in a major stock
market propagate in foreign markets as a process called nancial contagion Examples of this phe-
nomenon are clearly visible in historical series of asset prices Fig 5 illustrates one such case
The Hawkes diusion model introduced by 28 is an attempt to extend previous models of stock
prices to include nancial contagion Modern models for stock prices are typically built upon the model
popularised by 29 where the log returns on the stock follow geometric Brownian motion Whilst this
seminal paper was lauded by the economics community the model inadequately captured the fat
tails of the return distribution and so was not commonly used by traders 30 Merton 31 attempted
to incorporate heavy tails by including a Poisson jump process to model booms and crashes in the
stock returns this model is often called Merton diusion model The Hawkes diusion model extends
this model by replacing the Poisson jump process with a mutually-exciting HP so that crashes can
self-excite and propagate in a market and between global markets
The basic Hawkes diusion model describes the log returns of m assets X1     Xm where
each asset i  1     m has associated expected return i  R constant volatility i  R and standard
i t  t  0 The Brownian motions have constant correlation coecients
Brownian motion W X
ij  i j  1     m Jumps are added by a self- and mutually-exciting HP as per Denition 7 with
some selection of constants  and  with stochastic jump sizes Zit  t  0 The asset dynamics
are then assumed to satisfy
dXit  i dt  i dW X
i t  Zit dNit 
Hawkes Processes
The general Hawkes diusion model replaces the constant volatilities with stochastic volatilities
V1     Vm specied by the Heston model Each asset i  1     m has a long-term mean
volatility i  0 rate of returning to this mean i  0 volatility of the volatility i  0 and standard
i t  t  0 Correlation between the W X s is optional yet the eect would
Brownian motion W V
be dominated by the jump component Then the full dynamics are captured by
dXit  i dt cid112
dVit  ii  Vit dt  i
Vit dW V
i t 
Vit dW X
i t  Zit dNit 
cid112
However the added realism of the Hawkes diusion model comes at a high price The constant
volatility model requires 5m3m2 parameters to be t assuming Zi is characterised by two parame-
ters and the stochastic volatility extension requires an extra 3m parameters assuming i j  1     m
that EWiV WjV   0 In 28 hypothesis tests reject the Merton diusion model in favour of the
Hawkes diusion model however there are no tests for overtting the data for example Akaike or
Bayesian information criterion comparisons Remember that John Von Neumann reputedly claimed
that with four parameters I can t an elephant 32
For computational necessity the authors made a number of simplifying assumptions to reduce
the number of parameters to t such as the background intensity of crashes is the same for all
markets Even so the Hawkes diusion model was only able to be tted for pairs of markets m  2
instead of for the globe as a whole Since the model was calibrated to daily returns of market indices
historical data was easily available for exmaple from Google or Yahoo nance care had to be
taken to convert timezones and handle the dierent market opening and closing times The parameter
estimation method used by 28 was the generalised method of moments however the theoretical
moments derived satisfy long and convoluted equations
362 Mid-price changes and high-frequency trading
A simpler system to model is a single stocks price over time though there are many dierent prices
to consider For each stock one could use the last transaction price the best ask price the best bid
price or the mid-price dened as the average of best ask and best bid prices The last transaction
price includes inherent microstructure noise for example the bidask bounce and the best ask and
bid prices fail to represent the actions of both buyers and sellers in the market
Filimonov and Sornette 6 model the mid-price changes over time as a HP In particular they look
at long-term trends of the estimated branching ratio In this context n represents the proportion
of price moves that are not due to external market information but simply reactions to other market
participants This ratio can be seen as the quantication of the principle of economic reexivity The
authors conclude that the branching ratio has increased dramatically from 30 in 1998 to 70 in
Later that year 33 critiqued the test procedure used in this analysis Filimonov and Sornette
6 had worked with a dataset with timestamps accurate to a second and this often led to multiple
arrivals nominally at the same time which is an impossible event for simple point processes Fake
precision was achieved by adding Unif0 1 random fractions of seconds to all timestamps a technique
also used by 34 Lorenzen found that this method added an element of smoothing to the data which
gave it a better t to the model than the actual millisecond precision data The randomisation also
introduced bias to the HP parameter estimates particularly of  and  Lorenzen formed a crude
measure of high-frequency trading activity leading to an interesting correlation between this activity
and n over the observed period
Patrick J Laub et al
Fig 5 Example of mutual excitation in global markets This gure plots the cascade of declines in
international equity markets experienced between October 3 2008 and October 10 2008 in the US
Latin America LA UK Developed European countries EU and Developed countries in the Pacic
Data are hourly The rst observation of each price index series is normalised to 100 and the following
observations are normalised by the same factor Source MSCI MXRT international equity indices on
Bloomberg reproduced from 28
Remark 9 Fortunately we have received comments from referees suggesting other very important works
to consider which we will briey list here The importance of Bowsher 34 is highlighted as is the
series by Chavez-Demoulin et al 35 36 They point to the book by McNeil et al 37 where a section
is devoted to HP applications and stress the relevance of the Parisian school in applying HPs to
microstructure modelling for example the paper by Bacry et al 38
4 Parameter estimation
This section investigates the problem of generating parameters estimates cid98  cid98cid98cid98 given some
will omit the cid98 and t arguments from functions L  Lcid98 t l  lcid98 t t  t tcid98 and
t  t tcid98 The estimators are tested over simulated data for the sake of simplicity and lack
nite set of arrival times t  t1 t2     tk presumed to be from a HP For brevity the notation here
of relevant data Unfortunately this method bypasses the many signicant challenges raised by real
datasets challenges that caused 39 to state that
Hawkes Processes
Our overall conclusion is that calibrating the Hawkes process is akin to an excursion within a
mineeld that requires expert and careful testing before any conclusive step can be taken
The method considered is maximum likelihood estimation which begins by nding the likelihood
function and estimates the model parameters as the inputs which maximise this function
41 Likelihood function derivation
Daley and Vere-Jones 9 Proposition 72III give the following result
Theorem 3 Hawkes process likelihood Let N  be a regular point process on 0 T  for some nite
positive T  and let t1     tk denote a realisation of N  over 0 T  Then the likelihood L of N  is
expressible in the form
cid104 kcid89
cid105
cid90 T
cid16 
cid17
Proof First assume that the process is observed up to the time of the kth arrival The joint density
function from 1 is
L  f t1 t2     tk 
kcid89
This function can be written in terms of the conditional intensity function Rearrange 2 to nd ft
in terms of t as per 40
ft
1  F t
dt F t
1  F t
  d log1  F t
Integrate both sides over the interval tk t
u du  log1  F
t  log1  F
tk 
cid90 t
cid90 t
The HP is a simple point process meaning that multiple arrivals cannot occur at the same time
Hence F tk  0 as Tk1  tk and so
Further rearranging yields
t  1  exp
cid90 t
cid16 
u du  log1  F
cid17
t  
t exp
Thus the likelihood becomes
kcid89
kcid89
ti exp
cid90 ti
cid16 
cid17
cid104 kcid89
cid105
cid17
cid90 tk
cid17
cid90 t
cid16 
cid16 
Patrick J Laub et al
Now suppose that the process is observed over some time period 0 T   0 tk The likelihood will
then include the probability of seeing no arrivals in the time interval tk T 
1  F
T  
cid104 kcid89
cid105
cid104 kcid89
cid105
cid16 
cid17
cid90 T
Using the formulation of F t from 15 then
The completes the proof
42 Simplications for exponential decay
kcid88
cid90 tk
With the likelihood function from 16 the log-likelihood for the interval 0 tk can be derived as
ti 
u du 
ti  tk 
Note that the integral over 0 tk can be broken up into the segments 0 t1 t1 t2     tk1 tk and
therefore
Finally many of the terms of this double summation cancel out leaving
tk  tk  
tkti  e
 tk  
tkti  1
cid105
Note that here the nal summand is unnecessary though it is often included see 33 Substituting
 and  into 17 gives
kcid88
cid104
  
i1cid88
titj cid105  tk 
kcid88
cid104
cid105
tkti  1
tk 
u du 
u du 
This can be simplied in the case where  decays exponentially
tk 
 du 
utj  du
kcid88
cid88
cid90 ti1
k1cid88
u du 
cid90 tk
cid90 t1
 tk  
 tk  
 tk  
cid90 t1
cid90 ti1
k1cid88
cid90 ti1
icid88
k1cid88
cid90 ti1
k1cid88
icid88
cid104
icid88
k1cid88
titicid105
k1cid88
cid104
utj  du
utj  du
ti1tj   e
titj cid105
cid104
kcid88
Hawkes Processes
This direct approach is computationally infeasible as the rst terms double summation entails
Ok2 complexity Fortunately the similar structure of the inner summations allows l to be computed
with Ok complexity 41 42 For i  2     k let Ai cid80i1
i1cid88
titi1cid16
j1 etitj  so that
ti1tj cid17
i2cid88
titi1
Ai  e
ti1tj  e
With the added base case of A1  0 l can be rewritten as
log  Ai  tk 
tkti  1
kcid88
cid104
kcid88
titi11  Ai  1 
cid105
Ozaki 8 also gives the partial derivatives and the Hessian for this log-likelihood function Of
particular note is that each derivative calculation can be achieved in order Ok complexity when a
recursive approach similar to 20 is taken 43
Remark 10 The recursion implies that the joint process N t t is Markovian see Remark 122
of 44
43 Discussion
Understanding of the maximum likelihood estimation method for the HP has changed signicantly
over time The general form of the log-likelihood function 17 was known by Rubin 45 It was applied
to the HP by Ozaki 8 who derived 19 and the improved recursive form 21 Ozaki also found as
noted earlier an ecient method for calculating the derivatives and the Hessian matrix Consistency
asymptotic normality and eciency of the estimator were proved by Ogata 41
It is clear that the maximum likelihood estimation will usually be very eective for model t-
ting However 6 found that for small samples the estimator produces signicant bias encounters
many local optima and is highly sensitive to the selection of excitation function Additionally the
Ok complexity can render the method useless when samples become large remember that any it-
erative optimisation routine would calculate the likelihood function perhaps thousands of times The
R hawkes package thus implements this routine in C in an attempt to mitigate the performance
issues
This performance bottleneck is largely the cause of the latest trend of using the generalised
method of moments to perform parameter estimation Da Fonseca and Zaatour 20 state that the
procedure is instantaneous on their test sets The method uses sample moments and the sample
autocorrelation function which are smoothed via a rather arbitrary user-selected procedure
5 Goodness of t
This section outlines approaches to determining the appropriateness of a HPs model for point data
which is a critical link in their application
Patrick J Laub et al
51 Transformation to a Poisson process
Assessing the goodness of t for some point data to a Hawkes model is an important practical consid-
eration In performing this assessment the point process compensator is essential as is the random
time change theorem here adapted from 46
Theorem 4 Random time change theorem Say t1 t2     tk is a realisation over time 0 T  from
a point process with conditional intensity function  If  is positive over 0 T  and T    as
then the transformed points t1 t2     tk form a Poisson process with unit rate
The random time change theorem is fundamental to the model tting procedure called point
process residual analysis Original work 47 on residual analysis goes back to 48 49 and 50 Daley
and Vere-Joness Proposition 74IV 9 rewords and extends the theorem as follows
Theorem 5 Residual analysis Consider an unbounded increasing sequence of time points t1 t2   
in the half-line 0 and a monotonic continuous compensator  such that limt t   as
The transformed sequence t
2     t1 t2    whose counting process is denoted Nt is
a realisation of a unit rate Poisson process if and only if the original sequence t1 t2    is a realisation
from the point process dened by 
1 t
Hence equipped with a closed form of the compensator from 18 the quality of the statistical
inference can be ascertained using standard tness tests for Poisson processes Fig 6 shows a realisation
of a HP and the corresponding transformed process In Fig 6 t appears identical to N t They are
actually slightly dierent  is continuous however the similarity is expected due to DoobMeyer
decomposition of the compensator
52 Tests for Poisson process
521 Basic tests
an extensive treatment As a rst test one can run a hypothesis test to checkcid80
There are many procedures for testing whether a series of points form a Poisson process see 15 for
i t  Poit
If this initial test succeeds then the interarrival times
2  t
1 2 3     t
3  t
2   
iidExp1 A qualitative approach is to create a quantilequantile QQ
should be tested to ensure i
plot for i using the exponential distribution see for example Fig 7a Otherwise a quantitative
alternative is to run KolmogorovSmirnov or perhaps AndersonDarling tests
522 Test for independence
The next test after conrming there is reason to believe that the i are exponentially distributed
is to check their independence This can be done by looking for autocorrelation in the i sequence
Obviously zero autocorrelation does not imply independence but a non-zero amount would certainly
imply a non-Poisson model A visual examination can be conducted by plotting the points Ui1 Ui
If there are noticeable patterns then the i are autocorrelated Otherwise the points should look evenly
scattered see for example Fig 7b Quantitative extensions exist for example see Section 333 of 51
or serial correlation tests in 52
Hawkes Processes
Fig 6 An example of using the random time change theorem to transform a Hawkes process into a
unit rate Poisson process a A Hawkes process N t with     05 2 21 with the associated
b conditional intensity function and c compensator d The transformed process Nt where
i  ti
523 Lewis test
1 t
2     t
N are arrival times for a unit rate Poisson process then t
A statistical test with more power is the Lewis test as described by 53 Firstly it relies on the fact
N1t
that if t
are distributed as the order statistics of a uniform 0 1 random sample This observation is called
conditional uniformity and forms the basis for a test itself Lewis test relies on applying Durbins
modication introduced in 54 with a widely applicable treatment by 55
N      t
N  t
524 Brownian motion approximation test
An approximate test for Poissonity can be constructed by using the Brownian motion approximation
to the Poisson process This is to say the observed times are transformed to be approximately
Brownian motion and then known properties of Brownian motion sample paths can be used to accept
or reject the original sample
The motivation for this line of enquiry comes from Algorithm 74V of 9 which is described as
an approximate KolmogorovSmirnov-type test Unfortunately a typographical error causes the
algorithm as printed to produce incorrect answers for various signicance levels An alternative test
based on the Brownian motion approximation is proposed here
T for t  0 1 Donskers
invariance principle implies that as T   M t  t  0 1 converges in distribution to standard
Say that N t is a Poisson process of rate T  Dene M t  N t tT 
02040608010012002004006008001000NtENt02040608010012002040tEt02040608010012002004006008001000t20040060080002004006008001000NtENt20
Patrick J Laub et al
Fig 7 a QQ testing for iid Exp1 interarrival times b A qualitative autocorrelation test The
Uk values are dened as Uk  F t
k1  1  et
k  t
kt
k1
Brownian motion Bt  t  0 1 Fig 8 shows example realisations of M t for various T that at
least qualitatively are reasonable approximations to standard Brownian motion
random time M  0 1 given by
An alternative test is to utilise the rst arcsine law for Brownian motion which states that the
 arg max
s01
is arcsine distributed that is M  Beta12 12 Therefore the test takes a sequence of arrivals
observed over 0 T  and
1 transforms the arrivals to t
2 constructs the Brownian motion approximation M t as above nds the maximiser M and
3 accepts the unit-rate Poisson process hypothesis if M lies within the 2 1  2 quantiles of
kT which should be a Poisson process with rate T
2T     t
1T t
over 0 1
the Beta12 12 distribution otherwise it is rejected
As a nal note many other tests can be performed based on other properties of Brownian motion
For example the test could be based simply on noting that M 1  N0 1 and thus accepts if
M 1  Z2 Z12 and rejects otherwise
6 Simulation methods
Simulation is an increasingly indispensable tool in probability modelling Here we give details of three
fundamental approaches to producing realisations of HPs
61 Transformation methods
For general point processes a simulation algorithm is suggested by the converse of the random time
change theorem given in Section 51 In essence a unit rate Poisson process t
2    is transformed
1 t
0123401234ExpectedObserved00204060810020406081UkUk1Hawkes Processes
Fig 8 Realisations of Poisson process approximations to Brownian motion Plots ac use the
observed windows of T 10 100 and 10000 respectively Plot d is a direct simulation of Brownian
motion for comparison
by the inverse compensator 1 into any general point process dened by that compensator The
method sometimes called the inverse compensator method iteratively solves the equations
s ds
k1  t
cid90 tk1
for t1 t2    the desired point process see 56 and Algorithm 74III of 9
For HPs the algorithm was rst suggested by Ozaki 8 but did not state explicitly any relation
to time changes It instead focused on 14
u du   log1  F
cid90 t1
cid90 t
which relates the conditional cdf of the next arrival to the previous history of arrivals t1 t2     tk
and the specied t This relation means the next arrival time Tk1 can easily be generated by the
inverse transform method that is draw U  Unif0 1 then tk1 is found by solving
u du   logU  
For an exponentially decaying intensity the equation becomes
logU   tk1  tk  
e tk1ti 
tkticid17
kcid88
Solving for tk1 can be achieved in linear time using the recursion of 20 However if a dierent
excitation function is used then 22 must be solved numerically for example using Newtons method
43 which entails a signicant computational eort
cid90 tk1
cid16 kcid88
005102tMt005102tMt005120tMt005120tBt22
Patrick J Laub et al
62 Ogatas modied thinning algorithm
HP generation is a similar problem to inhomogeneous Poisson process generation The standard way to
generate a inhomogeneous Poisson process driven by intensity function  is via thinning Formally
the process is described by Algorithm 1 57 The intuition is to generate a faster homogeneous
Poisson process and remove points probabilistically so that the remaining points satisfy the time-
varying intensity  The rst process rate M cannot be less than  over 0 T 
A similar approach can be used for the HP called Ogatas modied thinning algorithm 43 44 The
conditional intensity  does not have an as asymptotic upper bound however it is common for
the intensity to be non-increasing in periods without any arrivals This implies that for t  Ti Ti1
t  T 
i  that is the time just after Ti when that arrival has been registered So the M
value can be updated during each simulation Algorithm 2 describes the process and Fig 9 shows an
example of each thinning procedure
Algorithm 1 Generate an inhomogeneous Poisson process by thinning
1 procedure PoissonByThinningT   M 
13 end procedure
require   M on 0 T 
P   t  0
while t  T do
E  ExpM 
t  t  E
U  Unif0 M 
if t  T and U  t then
end while
return P
P  P t
Algorithm 2 Generate a Hawkes process by thinning
1 procedure HawkesByThinningT  
require  non-increasing in periods of no arrivals
  1010 some tiny value  0
P   t  0
while t  T do
17 end procedure
end while
return P
Find new upper bound
M  t  
Generate next candidate point
E  ExpM  t  t  E
Keep it with some probability
U  Unif0 M 
if t  T and U  t then
P  P t
Hawkes Processes
Fig 9 Processes generated by thinning a A Poisson process with intensity t  2sint bounded
above by M  4 b A Hawkes process with     1 1 11 Each t U  point describes a
suggested arrival at time t whose U value is given in Algorithm 1 and Algorithm 2 Plus signs indicate
rejected points circles accepted and green squares the resulting point processes
63 Superposition of Poisson processes
The immigrationbirth representation gives rise to a simple simulation procedure generate the immi-
grant arrivals then generate the descendants for each immigrant Algorithm 3 describes the procedure
in full with Fig 10 showing an example realisation
immigrant i then EDi cid82 
Immigrants form a homogeneous Poisson process of rate  so over an interval 0 T  the number of
immigrants is PoiT  distributed Conditional on knowing that there are k immigrants their arrival
times C1 C2     Ck are distributed as the order statistics of iid Unif0 T  random variables
Each immigrants descendants form an inhomogeneous Poisson process The ith immigrants de-
scendants arrive with intensity t  Ci for t  Ci Denote Di to be the number of descendants of
iid Poin Say that the descendants of the
ith immigrant arrive at times Ci  E1 Ci  E2     Ci  EDi  Conditional on knowing Di the Ej
are iid random variables distributed with pdf n For exponentially decaying intensities this
simplies to Ej
0 s ds  n and hence Di
iid Exp
64 Other methods
This sections contents are by no means a complete compilation of simulation techniques available for
HPs Dassios and Zhao 58 and Mller and Rasmussen 59 give alternatives to the methods listed
above Also not discussed is the problem of simulating mutually-exciting HPs however there are many
02468101201234tUtMAcceptedRejected00511522533540246tUtMAcceptedRejected24
Patrick J Laub et al
Algorithm 3 Generate a Hawkes process by clusters
1 procedure HawkesByClustersT    
P  
Immigrants
 Unif0 T 
 Poi
k  PoiT 
C1 C2     Ck
Descendants
D1 D2     Dk
for i  1 to k do
if Di  0 then
E1 E2     EDi
P  P  Ci  E1     Ci  EDi
 Exp
19 end procedure
return P
end for
Remove descendants outside 0 T 
Add in immigrants and sort
P  Pi  Pi  P Pi  T
P  SortP  C1 C2     Ck
Fig 10 A Hawkes Poisson process generated by clusters Plot a shows the points generated by
the immigrantbirth representation it can be seen as a sequence of vertically stacked family trees
The immigrant points are plotted as squares following circles of the same height and color are its
ospring The intensity function with     1 2 12 is plotted in b The resulting Hawkes
process arrivals are drawn as crosses on the axis
free software packages that provide this functionality Fig 11 shows an example realisation generated
using the R package hawkes see also Roger D Pengs related R package ptproc
0123456789100246810tFamilyNumber0123456789100246810tIntensityHawkes Processes
Fig 11 A pair of mutually exciting Hawkes processes a The two counting processes N1t and N2t
with parameters 1  2  1 11  12  21  22  2 11  12  21  22  8 b The
processes realised intensitites note that 
2t so only one is plotted
1t  
7 Conclusion
HPs are fundamentally fascinating models of reality Many of the standard probability models are
Markovian and hence disregard the history of the process The HP is structured around the premise
that the history matters which partly explains why they appear in such a broad range of applications
If the exponentially decaying intensity can be utilised then the joint process N   satises
the Markov condition and both processes exhibit amazing analytical tractability Explosion is avoided
by ensuring that    The covariance density is a simple symmetric scaled exponential curve and the
power spectral density is a shifted scaled Cauchy pdf The likelihood function and the compensator
are elegant and ecient to calculate using recursive structures Exact simulation algorithms can
generate this type of HP with optimal eciency Many aspects of the HP remain obtainable with any
selection of excitation function for example the random time change theorem completely solves the
problem of testing the goodness of a models t
The use of HPs in nance appears itself to have been a self-exciting process At-Sahalia et al
28 Filimonov and Sornette 6 and Da Fonseca and Zaatour 20 formed the primary sources for the
nancial part of Section 3 these papers are surprisingly recent given the fact that the model was
introduced in 1971 and are representative of a current surge in HP research
A Additional proof details
In this appendix we collect additional detail elided from the proof of Theorem 2
0102030405060708090100050100150200tCounts01020304050607080901000510tIntensity26
Patrick J Laub et al
A1 Supplementary to Theorem 2 part one
R   E
 dN t
cid32
cid21
cid20 dN t
cid34
cid90 t
 dN t
cid90 t
cid35
t    s dN s
cid32cid90 t
t    s dN s
cid33  2
cid33  2
cid35
 2
   E
t    s dN s
cid34cid90 
Introduce a change of variable v  s  t and multiply by dv
 2
R     E
  v
dN t  v
The expectation is a shifted Rcv Substitute that and 8 in
R    
  
     
cid90 
cid90 
  
cid90 
  vcid0Rcv  2cid1 dv  2
dv  2cid90 
cid90 
 2
  vRv dv     1  n 
  vRv dv  n2
v  Rv
  v
cid16
cid17
cid90 
  1  n    1  n
 R     
cid90 
1  n
  vRv dv 
   
Using 7 yields
cid20 dN t
cid21
dN t  v
dv  2
  vE
  v dv  2
A2 Supplementary to Theorem 2 part two
Split the right-hand side of the equation into three functions g1 g2 and g3
  vRv dv
  vRv dv
cid90 
cid124
cid125
cid123cid122
g3 
cid125
Taking the Laplace transform of each term gives
R    
g2 
cid123cid122
g1 
cid90 
cid124
cid124 cid123cid122 cid125
cid90 s
Lcid8g1 cid9 s 
cid90 
Lcid8g2 cid9 s 
cid90 
cid90 
s e
 d 
 
 vRv dv d
 s d dv
cid90 
vRv
cid90 
vRv dv
L R  
Hawkes Processes
Therefore the Laplace transform of 23
Lcid8g3 cid9 s  Lcid8 cid9 sLcid8R cid9 s 
Lcid8R cid9 s 
cid16
  Lcid8R cid9   Lcid8R cid9 s
Lcid8R cid9 s 
cid17
Substituting s   and rearranging gives that
Lcid8R cid9  
So substituting the value of Lcid8R cid9  into 24 means

2  
Lcid8R cid9 s 
 Lcid8R cid9 s 
cid16
 
cid16
  
2
1  

cid17
2  
cid17
 Lcid8R cid9 s
2  
2  s    
References
1 Y Ogata Journal of the American Statistical Association 83401 9 1988
2 GO Mohler MB Short PJ Brantingham FP Schoenberg GE Tita Journal of the American Statistical
Association 106493 100 2011
3 S Azizpour K Giesecke G Schwenkler Exploring the sources of default clustering httpwebstanfordedu
deptMSandEcgi-binpeoplefacultygieseckepdfsexploringpdf 2010 Working paper retrieved on 10
Feb 2015
4 AG Hawkes Biometrika 581 83 1971
5 D Lando MS Nielsen Journal of Financial Intermediation 193 355 2010
6 V Filimonov D Sornette Physical Review E 855 056108 2012
7 L Carstensen Hawkes processes and combinatorial transcriptional regulation PhD thesis University of Copen-
hagen 2010
8 T Ozaki Annals of the Institute of Statistical Mathematics 311 145 1979
9 D Daley D Vere-Jones An Introduction to the Theory of Point Processes Volume I Elementary Theory and
Methods Springer 2003
10 DR Cox Journal of the Royal Statistical Society Series B Methodological 172 129 1955
11 MS Bartlett Journal of the Royal Statistical Society Series B Methodological 252 264 1963
12 MS Bartlett Sankhya The Indian Journal of Statistics Series A 253 245 1963
13 MS Bartlett Biometrika 5134 299 1964
14 PA Lewis Journal of the Royal Statistical Society Series B Methodological 263 398 1964
15 DR Cox PA Lewis The Statistical Analysis of Series of Events Monographs on Applied Probability and
Statistics London Chapman and Hall 1966
16 AG Hawkes Journal of the Royal Statistical Society Series B Methodological 333 438 1971
17 N Hautsch Econometrics of Financial High-Frequency Data Springer 2011
18 Y Ogata Pure and Applied Geophysics 15524 471 1999
19 V Chatalbashev Y Liang A Ocer N Trichakis Exciting times for trade arrivals httpusersiems
northwesterneduarmbruster2007msande444report1apdf 2007 Stanford University MSE 444 group
project submission retrieved on 10 Feb 2015
20 J Da Fonseca R Zaatour Journal of Futures Markets 346 548 2014
21 AG Hawkes D Oakes Journal of Applied Probability 113 493 1974
22 JG Rasmussen Methodology and Computing in Applied Probability 153 623 2013
23 G Grimmett D Stirzaker Probability and Random Processes Oxford University Press 2001
24 S Asmussen Applied Probability and Queues 2nd edn Applications of Mathematics Stochastic Modelling and
Applied Probability Springer 2003
25 PA Lewis Journal of Sound and Vibration 123 353 1970
26 P Bremaud L Massoulie The Annals of Probability 243 1563 1996
Patrick J Laub et al
27 L Zhu Journal of Applied Probability 503 760 2013
28 Y At-Sahalia J Cacho-Diaz RJ Laeven Modeling nancial contagion using mutually exciting jump processes
Tech Rep 15850 National Bureau of Economic Research USA 2010
29 F Black M Scholes The Journal of Political Economy 813 637 1973
30 EG Haug NN Taleb Wilmott Magazine 71 2014
31 RC Merton Journal of Financial Economics 31 125 1976
32 F Dyson Nature 4276972 297 2004
33 F Lorenzen Analysis of order clustering using high frequency data A point process approach PhD thesis
Swiss Federal Institute of Technology Zurich ETH Zurich 2012
34 CG Bowsher Journal of Econometrics 1412 876 2007
35 V Chavez-Demoulin AC Davison AJ McNeil Quantitative Finance 52 227 2005
36 V Chavez-Demoulin J McGill Journal of Banking  Finance 3612 3415 2012
37 AJ McNeil R Frey P Embrechts Quantitative Risk Management Concepts Techniques and Tools Concepts
Techniques and Tools Princeton university press 2015
38 E Bacry S Delattre M Homann JF Muzy Quantitative Finance 131 65 2013
39 V Filimonov D Sornette Apparent criticality and calibration issues in the Hawkes self-excited point process
model application to high-frequency nancial data Tech Rep 13-60 Swiss Finance Institute Research Paper
40 JG Rasmussen Temporal point processes the conditional intensity function httppeoplemathaaudk
jgrteachingpunktproc11tpppdf 2009 Course notes for rumlige punktprocesser spatial point processes
retrieved on 10 Feb 2015
41 Y Ogata Annals of the Institute of Statistical Mathematics 301 243 1978
42 S Crowley Point process models for multivariate high-frequency irregularly spaced data httpvixraorg
pdf12110094v6pdf 2013 Working paper retrieved on 10 Feb 2015
43 Y Ogata Information Theory IEEE Transactions on 271 23 1981
44 TJ Liniger Multivariate Hawkes processes PhD thesis Swiss Federal Institute of Technology Zurich ETH
Zurich 2009
45 I Rubin Information Theory IEEE Transactions on 185 547 1972
46 E Brown R Barbieri V Ventura R Kass L Frank Neural computation 142 325 2002
47 P Embrechts T Liniger L Lin Journal of Applied Probability 48A 367 2011 Special volume a Festschrift
for Sren Asmussen
48 PA Meyer in Seminaire de Probabilites V Universite de Strasbourg Springer 1971 pp 191195
49 F Papangelou Transactions of the American Mathematical Society 165 483 1972
50 S Watanabe Japan J Math 3453-70 82 1964
51 DE Knuth Art of Computer Programming Volume 2 Seminumerical Algorithms The Addison-Wesley Pro-
fessional 2014
52 D Kroese T Taimre ZI Botev Handbook of Monte Carlo methods Wiley 2011
53 SH Kim W Whitt The power of alternative KolmogorovSmirnov tests based on transformations of the data
2013 Submitted to ACM Transactions on Modeling and Computer Simulation Special Issue in Honor of Don
Iglehart Issue 254
54 J Durbin Biometrika 5334 41 1961
55 PA Lewis Biometrika 5212 67 1965
56 K Giesecke P Tomecek Dependent events and changes of time httpwebstanfordedudeptMSandE
cgi-binpeoplefacultygieseckepdfsdectpdf 2005 Working paper retrieved on 10 Feb 2015
57 PA Lewis GS Shedler Naval Research Logistics Quarterly 263 403 1979
58 A Dassios H Zhao Electronic Communications in Probability 1862 2013
59 J Mller JG Rasmussen Advances in Applied Probability 373 629 2005
