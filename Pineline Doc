Pineline Doc

This is a document to go over the steps to create the corpus of text to parse with NLPTK

Note: all 'creation' programs run on Python 2.7x

######
Steps
######

Note: this is using the arXiv database and API

1. Go to (https://arxiv.org/) and go to the search you would like to pull the articles from

2. After you do the search query, in the website path, put the string that is after "query=" in the search_query variable in the arXiv_API_test.py
For example: http://search.arxiv.org:8081/?query=galaxy+evolution&in=grp_physics   would be galaxy+evolution&in=grp_physics

3. Decide on how many articles you would like and put that number in the max_results variable in arXiv_API_test.py

4. Make sure links_for_pdfs.txt is an empty file

5. Run arXiv_API_test.py, this will output all of the links to download all of the pdfs in query

6. Make sure the PDFs folder is empty

7. Run download_pdf.py, this will download all of the PDF's to the PDFs file in question

8. Make sure pdfout.txt is empty

9. Set the variable NUM_OF_PDF in PDFparser to the desired number of pdfs you would like turned into text

10. Run PDFparser.py, this will generate the corpus of text for the query given

11. Run filter.py, Filter out the pictures and random lines of the text.


###########################
The corpus is now created!
###########################

Note: At this point switch back to Python 3.5x


http://www.nltk.org/book/ch03.html





